{
 "nbformat": 4,
 "nbformat_minor": 0,
 "metadata": {
  "colab": {
   "provenance": [],
   "gpuType": "A100",
   "authorship_tag": "ABX9TyNw4RRwaHqG/jJekgRIjTJG"
  },
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3"
  },
  "language_info": {
   "name": "python"
  },
  "accelerator": "GPU"
 },
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "m5-Chg9X2SkH",
    "outputId": "48f5eee2-06ce-40bc-a13f-f672092727ea",
    "executionInfo": {
     "status": "ok",
     "timestamp": 1742461411327,
     "user_tz": -120,
     "elapsed": 4070847,
     "user": {
      "displayName": "Konstantinos Roumeliotis",
      "userId": "17264923090131634662"
     }
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Requirement already satisfied: torch in /usr/local/lib/python3.11/dist-packages (2.6.0+cu124)\n",
      "Requirement already satisfied: torchvision in /usr/local/lib/python3.11/dist-packages (0.21.0+cu124)\n",
      "Requirement already satisfied: pandas in /usr/local/lib/python3.11/dist-packages (2.2.2)\n",
      "Requirement already satisfied: pillow in /usr/local/lib/python3.11/dist-packages (11.1.0)\n",
      "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.11/dist-packages (1.6.1)\n",
      "Collecting optuna\n",
      "  Downloading optuna-4.2.1-py3-none-any.whl.metadata (17 kB)\n",
      "Requirement already satisfied: tqdm in /usr/local/lib/python3.11/dist-packages (4.67.1)\n",
      "Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from torch) (3.17.0)\n",
      "Requirement already satisfied: typing-extensions>=4.10.0 in /usr/local/lib/python3.11/dist-packages (from torch) (4.12.2)\n",
      "Requirement already satisfied: networkx in /usr/local/lib/python3.11/dist-packages (from torch) (3.4.2)\n",
      "Requirement already satisfied: jinja2 in /usr/local/lib/python3.11/dist-packages (from torch) (3.1.6)\n",
      "Requirement already satisfied: fsspec in /usr/local/lib/python3.11/dist-packages (from torch) (2024.10.0)\n",
      "Collecting nvidia-cuda-nvrtc-cu12==12.4.127 (from torch)\n",
      "  Downloading nvidia_cuda_nvrtc_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
      "Collecting nvidia-cuda-runtime-cu12==12.4.127 (from torch)\n",
      "  Downloading nvidia_cuda_runtime_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
      "Collecting nvidia-cuda-cupti-cu12==12.4.127 (from torch)\n",
      "  Downloading nvidia_cuda_cupti_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
      "Collecting nvidia-cudnn-cu12==9.1.0.70 (from torch)\n",
      "  Downloading nvidia_cudnn_cu12-9.1.0.70-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
      "Collecting nvidia-cublas-cu12==12.4.5.8 (from torch)\n",
      "  Downloading nvidia_cublas_cu12-12.4.5.8-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
      "Collecting nvidia-cufft-cu12==11.2.1.3 (from torch)\n",
      "  Downloading nvidia_cufft_cu12-11.2.1.3-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
      "Collecting nvidia-curand-cu12==10.3.5.147 (from torch)\n",
      "  Downloading nvidia_curand_cu12-10.3.5.147-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
      "Collecting nvidia-cusolver-cu12==11.6.1.9 (from torch)\n",
      "  Downloading nvidia_cusolver_cu12-11.6.1.9-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
      "Collecting nvidia-cusparse-cu12==12.3.1.170 (from torch)\n",
      "  Downloading nvidia_cusparse_cu12-12.3.1.170-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
      "Requirement already satisfied: nvidia-cusparselt-cu12==0.6.2 in /usr/local/lib/python3.11/dist-packages (from torch) (0.6.2)\n",
      "Requirement already satisfied: nvidia-nccl-cu12==2.21.5 in /usr/local/lib/python3.11/dist-packages (from torch) (2.21.5)\n",
      "Requirement already satisfied: nvidia-nvtx-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch) (12.4.127)\n",
      "Collecting nvidia-nvjitlink-cu12==12.4.127 (from torch)\n",
      "  Downloading nvidia_nvjitlink_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
      "Requirement already satisfied: triton==3.2.0 in /usr/local/lib/python3.11/dist-packages (from torch) (3.2.0)\n",
      "Requirement already satisfied: sympy==1.13.1 in /usr/local/lib/python3.11/dist-packages (from torch) (1.13.1)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from sympy==1.13.1->torch) (1.3.0)\n",
      "Requirement already satisfied: numpy in /usr/local/lib/python3.11/dist-packages (from torchvision) (2.0.2)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.11/dist-packages (from pandas) (2.8.2)\n",
      "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.11/dist-packages (from pandas) (2025.1)\n",
      "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.11/dist-packages (from pandas) (2025.1)\n",
      "Requirement already satisfied: scipy>=1.6.0 in /usr/local/lib/python3.11/dist-packages (from scikit-learn) (1.14.1)\n",
      "Requirement already satisfied: joblib>=1.2.0 in /usr/local/lib/python3.11/dist-packages (from scikit-learn) (1.4.2)\n",
      "Requirement already satisfied: threadpoolctl>=3.1.0 in /usr/local/lib/python3.11/dist-packages (from scikit-learn) (3.6.0)\n",
      "Collecting alembic>=1.5.0 (from optuna)\n",
      "  Downloading alembic-1.15.1-py3-none-any.whl.metadata (7.2 kB)\n",
      "Collecting colorlog (from optuna)\n",
      "  Downloading colorlog-6.9.0-py3-none-any.whl.metadata (10 kB)\n",
      "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.11/dist-packages (from optuna) (24.2)\n",
      "Requirement already satisfied: sqlalchemy>=1.4.2 in /usr/local/lib/python3.11/dist-packages (from optuna) (2.0.39)\n",
      "Requirement already satisfied: PyYAML in /usr/local/lib/python3.11/dist-packages (from optuna) (6.0.2)\n",
      "Collecting Mako (from alembic>=1.5.0->optuna)\n",
      "  Downloading Mako-1.3.9-py3-none-any.whl.metadata (2.9 kB)\n",
      "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.11/dist-packages (from python-dateutil>=2.8.2->pandas) (1.17.0)\n",
      "Requirement already satisfied: greenlet!=0.4.17 in /usr/local/lib/python3.11/dist-packages (from sqlalchemy>=1.4.2->optuna) (3.1.1)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.11/dist-packages (from jinja2->torch) (3.0.2)\n",
      "Downloading nvidia_cublas_cu12-12.4.5.8-py3-none-manylinux2014_x86_64.whl (363.4 MB)\n",
      "\u001B[2K   \u001B[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001B[0m \u001B[32m363.4/363.4 MB\u001B[0m \u001B[31m2.3 MB/s\u001B[0m eta \u001B[36m0:00:00\u001B[0m\n",
      "\u001B[?25hDownloading nvidia_cuda_cupti_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (13.8 MB)\n",
      "\u001B[2K   \u001B[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001B[0m \u001B[32m13.8/13.8 MB\u001B[0m \u001B[31m71.9 MB/s\u001B[0m eta \u001B[36m0:00:00\u001B[0m\n",
      "\u001B[?25hDownloading nvidia_cuda_nvrtc_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (24.6 MB)\n",
      "\u001B[2K   \u001B[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001B[0m \u001B[32m24.6/24.6 MB\u001B[0m \u001B[31m73.8 MB/s\u001B[0m eta \u001B[36m0:00:00\u001B[0m\n",
      "\u001B[?25hDownloading nvidia_cuda_runtime_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (883 kB)\n",
      "\u001B[2K   \u001B[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001B[0m \u001B[32m883.7/883.7 kB\u001B[0m \u001B[31m51.3 MB/s\u001B[0m eta \u001B[36m0:00:00\u001B[0m\n",
      "\u001B[?25hDownloading nvidia_cudnn_cu12-9.1.0.70-py3-none-manylinux2014_x86_64.whl (664.8 MB)\n",
      "\u001B[2K   \u001B[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001B[0m \u001B[32m664.8/664.8 MB\u001B[0m \u001B[31m1.3 MB/s\u001B[0m eta \u001B[36m0:00:00\u001B[0m\n",
      "\u001B[?25hDownloading nvidia_cufft_cu12-11.2.1.3-py3-none-manylinux2014_x86_64.whl (211.5 MB)\n",
      "\u001B[2K   \u001B[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001B[0m \u001B[32m211.5/211.5 MB\u001B[0m \u001B[31m9.8 MB/s\u001B[0m eta \u001B[36m0:00:00\u001B[0m\n",
      "\u001B[?25hDownloading nvidia_curand_cu12-10.3.5.147-py3-none-manylinux2014_x86_64.whl (56.3 MB)\n",
      "\u001B[2K   \u001B[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001B[0m \u001B[32m56.3/56.3 MB\u001B[0m \u001B[31m35.4 MB/s\u001B[0m eta \u001B[36m0:00:00\u001B[0m\n",
      "\u001B[?25hDownloading nvidia_cusolver_cu12-11.6.1.9-py3-none-manylinux2014_x86_64.whl (127.9 MB)\n",
      "\u001B[2K   \u001B[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001B[0m \u001B[32m127.9/127.9 MB\u001B[0m \u001B[31m7.8 MB/s\u001B[0m eta \u001B[36m0:00:00\u001B[0m\n",
      "\u001B[?25hDownloading nvidia_cusparse_cu12-12.3.1.170-py3-none-manylinux2014_x86_64.whl (207.5 MB)\n",
      "\u001B[2K   \u001B[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001B[0m \u001B[32m207.5/207.5 MB\u001B[0m \u001B[31m10.0 MB/s\u001B[0m eta \u001B[36m0:00:00\u001B[0m\n",
      "\u001B[?25hDownloading nvidia_nvjitlink_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (21.1 MB)\n",
      "\u001B[2K   \u001B[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001B[0m \u001B[32m21.1/21.1 MB\u001B[0m \u001B[31m100.2 MB/s\u001B[0m eta \u001B[36m0:00:00\u001B[0m\n",
      "\u001B[?25hDownloading optuna-4.2.1-py3-none-any.whl (383 kB)\n",
      "\u001B[2K   \u001B[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001B[0m \u001B[32m383.6/383.6 kB\u001B[0m \u001B[31m31.3 MB/s\u001B[0m eta \u001B[36m0:00:00\u001B[0m\n",
      "\u001B[?25hDownloading alembic-1.15.1-py3-none-any.whl (231 kB)\n",
      "\u001B[2K   \u001B[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001B[0m \u001B[32m231.8/231.8 kB\u001B[0m \u001B[31m22.5 MB/s\u001B[0m eta \u001B[36m0:00:00\u001B[0m\n",
      "\u001B[?25hDownloading colorlog-6.9.0-py3-none-any.whl (11 kB)\n",
      "Downloading Mako-1.3.9-py3-none-any.whl (78 kB)\n",
      "\u001B[2K   \u001B[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001B[0m \u001B[32m78.5/78.5 kB\u001B[0m \u001B[31m8.2 MB/s\u001B[0m eta \u001B[36m0:00:00\u001B[0m\n",
      "\u001B[?25hInstalling collected packages: nvidia-nvjitlink-cu12, nvidia-curand-cu12, nvidia-cufft-cu12, nvidia-cuda-runtime-cu12, nvidia-cuda-nvrtc-cu12, nvidia-cuda-cupti-cu12, nvidia-cublas-cu12, Mako, colorlog, nvidia-cusparse-cu12, nvidia-cudnn-cu12, alembic, optuna, nvidia-cusolver-cu12\n",
      "  Attempting uninstall: nvidia-nvjitlink-cu12\n",
      "    Found existing installation: nvidia-nvjitlink-cu12 12.5.82\n",
      "    Uninstalling nvidia-nvjitlink-cu12-12.5.82:\n",
      "      Successfully uninstalled nvidia-nvjitlink-cu12-12.5.82\n",
      "  Attempting uninstall: nvidia-curand-cu12\n",
      "    Found existing installation: nvidia-curand-cu12 10.3.6.82\n",
      "    Uninstalling nvidia-curand-cu12-10.3.6.82:\n",
      "      Successfully uninstalled nvidia-curand-cu12-10.3.6.82\n",
      "  Attempting uninstall: nvidia-cufft-cu12\n",
      "    Found existing installation: nvidia-cufft-cu12 11.2.3.61\n",
      "    Uninstalling nvidia-cufft-cu12-11.2.3.61:\n",
      "      Successfully uninstalled nvidia-cufft-cu12-11.2.3.61\n",
      "  Attempting uninstall: nvidia-cuda-runtime-cu12\n",
      "    Found existing installation: nvidia-cuda-runtime-cu12 12.5.82\n",
      "    Uninstalling nvidia-cuda-runtime-cu12-12.5.82:\n",
      "      Successfully uninstalled nvidia-cuda-runtime-cu12-12.5.82\n",
      "  Attempting uninstall: nvidia-cuda-nvrtc-cu12\n",
      "    Found existing installation: nvidia-cuda-nvrtc-cu12 12.5.82\n",
      "    Uninstalling nvidia-cuda-nvrtc-cu12-12.5.82:\n",
      "      Successfully uninstalled nvidia-cuda-nvrtc-cu12-12.5.82\n",
      "  Attempting uninstall: nvidia-cuda-cupti-cu12\n",
      "    Found existing installation: nvidia-cuda-cupti-cu12 12.5.82\n",
      "    Uninstalling nvidia-cuda-cupti-cu12-12.5.82:\n",
      "      Successfully uninstalled nvidia-cuda-cupti-cu12-12.5.82\n",
      "  Attempting uninstall: nvidia-cublas-cu12\n",
      "    Found existing installation: nvidia-cublas-cu12 12.5.3.2\n",
      "    Uninstalling nvidia-cublas-cu12-12.5.3.2:\n",
      "      Successfully uninstalled nvidia-cublas-cu12-12.5.3.2\n",
      "  Attempting uninstall: nvidia-cusparse-cu12\n",
      "    Found existing installation: nvidia-cusparse-cu12 12.5.1.3\n",
      "    Uninstalling nvidia-cusparse-cu12-12.5.1.3:\n",
      "      Successfully uninstalled nvidia-cusparse-cu12-12.5.1.3\n",
      "  Attempting uninstall: nvidia-cudnn-cu12\n",
      "    Found existing installation: nvidia-cudnn-cu12 9.3.0.75\n",
      "    Uninstalling nvidia-cudnn-cu12-9.3.0.75:\n",
      "      Successfully uninstalled nvidia-cudnn-cu12-9.3.0.75\n",
      "  Attempting uninstall: nvidia-cusolver-cu12\n",
      "    Found existing installation: nvidia-cusolver-cu12 11.6.3.83\n",
      "    Uninstalling nvidia-cusolver-cu12-11.6.3.83:\n",
      "      Successfully uninstalled nvidia-cusolver-cu12-11.6.3.83\n",
      "Successfully installed Mako-1.3.9 alembic-1.15.1 colorlog-6.9.0 nvidia-cublas-cu12-12.4.5.8 nvidia-cuda-cupti-cu12-12.4.127 nvidia-cuda-nvrtc-cu12-12.4.127 nvidia-cuda-runtime-cu12-12.4.127 nvidia-cudnn-cu12-9.1.0.70 nvidia-cufft-cu12-11.2.1.3 nvidia-curand-cu12-10.3.5.147 nvidia-cusolver-cu12-11.6.1.9 nvidia-cusparse-cu12-12.3.1.170 nvidia-nvjitlink-cu12-12.4.127 optuna-4.2.1\n",
      "Mounted at /content/gdrive\n",
      "Using device: cuda\n",
      "GPU: NVIDIA A100-SXM4-40GB\n",
      "Memory Allocated: 0.00 GB\n",
      "Memory Reserved: 0.00 GB\n",
      "Total Memory: 42.47 GB\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "[I 2025-03-20 07:57:34,819] A new study created in memory with name: no-name-96d5af4e-18ba-45a7-8785-4dffe1b8c820\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Label encoding saved to /content/gdrive/My Drive/Projects/Multimodal/Datasets/corn-label_to_idx-100.json\n",
      "Number of classes: 4\n",
      "Running 30 trials with larger batch sizes to maximize GPU usage\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "Downloading: \"https://download.pytorch.org/models/resnet50-0676ba61.pth\" to /root/.cache/torch/hub/checkpoints/resnet50-0676ba61.pth\n",
      "100%|██████████| 97.8M/97.8M [00:00<00:00, 189MB/s]\n",
      "<ipython-input-1-7ef836402601>:313: FutureWarning: `torch.cuda.amp.GradScaler(args...)` is deprecated. Please use `torch.amp.GradScaler('cuda', args...)` instead.\n",
      "  scaler = amp.GradScaler()\n",
      "Training:   0%|          | 0/8 [00:00<?, ?it/s]<ipython-input-1-7ef836402601>:230: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with amp.autocast():\n",
      "Training: 100%|██████████| 8/8 [00:34<00:00,  4.26s/it]\n",
      "<ipython-input-1-7ef836402601>:256: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with torch.no_grad(), amp.autocast():\n",
      "Validating: 100%|██████████| 2/2 [00:31<00:00, 16.00s/it]\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Epoch 1, Train Loss: 1.4176, Train Acc: 0.2949, Val Loss: 1.3554, Val Acc: 0.3438\n",
      "GPU Memory: 0.11GB / 42.47GB\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "Training: 100%|██████████| 8/8 [00:30<00:00,  3.82s/it]\n",
      "Validating: 100%|██████████| 2/2 [00:00<00:00,  9.59it/s]\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Epoch 2, Train Loss: 1.3238, Train Acc: 0.3594, Val Loss: 1.2665, Val Acc: 0.3281\n",
      "GPU Memory: 0.11GB / 42.47GB\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "Training: 100%|██████████| 8/8 [00:26<00:00,  3.27s/it]\n",
      "Validating: 100%|██████████| 2/2 [00:00<00:00,  9.77it/s]\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Epoch 3, Train Loss: 1.2320, Train Acc: 0.4434, Val Loss: 1.1676, Val Acc: 0.5469\n",
      "GPU Memory: 0.11GB / 42.47GB\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "Training: 100%|██████████| 8/8 [00:23<00:00,  2.91s/it]\n",
      "Validating: 100%|██████████| 2/2 [00:00<00:00,  9.92it/s]\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Epoch 4, Train Loss: 1.1825, Train Acc: 0.5273, Val Loss: 1.1092, Val Acc: 0.5469\n",
      "GPU Memory: 0.11GB / 42.47GB\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "Training: 100%|██████████| 8/8 [00:22<00:00,  2.84s/it]\n",
      "Validating: 100%|██████████| 2/2 [00:00<00:00, 10.65it/s]\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Epoch 5, Train Loss: 1.1330, Train Acc: 0.5508, Val Loss: 1.0512, Val Acc: 0.5781\n",
      "GPU Memory: 0.11GB / 42.47GB\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "Training: 100%|██████████| 8/8 [00:19<00:00,  2.43s/it]\n",
      "Validating: 100%|██████████| 2/2 [00:00<00:00, 10.69it/s]\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Epoch 6, Train Loss: 1.0668, Train Acc: 0.5898, Val Loss: 1.0120, Val Acc: 0.5625\n",
      "GPU Memory: 0.11GB / 42.47GB\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "Training: 100%|██████████| 8/8 [00:16<00:00,  2.05s/it]\n",
      "Validating: 100%|██████████| 2/2 [00:00<00:00,  9.74it/s]\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Epoch 7, Train Loss: 0.9877, Train Acc: 0.6426, Val Loss: 0.9488, Val Acc: 0.6094\n",
      "GPU Memory: 0.11GB / 42.47GB\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "Training: 100%|██████████| 8/8 [00:15<00:00,  1.90s/it]\n",
      "Validating: 100%|██████████| 2/2 [00:00<00:00, 10.95it/s]\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Epoch 8, Train Loss: 0.9285, Train Acc: 0.6758, Val Loss: 0.9150, Val Acc: 0.6250\n",
      "GPU Memory: 0.11GB / 42.47GB\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "Training: 100%|██████████| 8/8 [00:13<00:00,  1.63s/it]\n",
      "Validating: 100%|██████████| 2/2 [00:00<00:00, 10.47it/s]\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Epoch 9, Train Loss: 0.9327, Train Acc: 0.6738, Val Loss: 0.8773, Val Acc: 0.6953\n",
      "GPU Memory: 0.11GB / 42.47GB\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "Training: 100%|██████████| 8/8 [00:11<00:00,  1.46s/it]\n",
      "Validating: 100%|██████████| 2/2 [00:00<00:00,  9.87it/s]\n",
      "[I 2025-03-20 08:01:43,712] Trial 0 finished with value: 0.6953125 and parameters: {'batch_size': 64, 'learning_rate': 0.00027289549831079545, 'dropout_rate': 0.5139929491921511, 'weight_decay': 3.442629667658055e-05}. Best is trial 0 with value: 0.6953125.\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Epoch 10, Train Loss: 0.8841, Train Acc: 0.6875, Val Loss: 0.8633, Val Acc: 0.6797\n",
      "GPU Memory: 0.11GB / 42.47GB\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "<ipython-input-1-7ef836402601>:313: FutureWarning: `torch.cuda.amp.GradScaler(args...)` is deprecated. Please use `torch.amp.GradScaler('cuda', args...)` instead.\n",
      "  scaler = amp.GradScaler()\n",
      "Training:   0%|          | 0/32 [00:00<?, ?it/s]<ipython-input-1-7ef836402601>:230: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with amp.autocast():\n",
      "Training: 100%|██████████| 32/32 [00:32<00:00,  1.00s/it]\n",
      "<ipython-input-1-7ef836402601>:256: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with torch.no_grad(), amp.autocast():\n",
      "Validating: 100%|██████████| 8/8 [00:08<00:00,  1.11s/it]\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Epoch 1, Train Loss: 1.3877, Train Acc: 0.3125, Val Loss: 1.1492, Val Acc: 0.6172\n",
      "GPU Memory: 0.21GB / 42.47GB\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "Training: 100%|██████████| 32/32 [00:29<00:00,  1.08it/s]\n",
      "Validating: 100%|██████████| 8/8 [00:00<00:00, 54.37it/s]\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Epoch 2, Train Loss: 1.2000, Train Acc: 0.4727, Val Loss: 0.9628, Val Acc: 0.7422\n",
      "GPU Memory: 0.21GB / 42.47GB\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "Training: 100%|██████████| 32/32 [00:26<00:00,  1.22it/s]\n",
      "Validating: 100%|██████████| 8/8 [00:00<00:00, 56.54it/s]\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Epoch 3, Train Loss: 1.0502, Train Acc: 0.5645, Val Loss: 0.9055, Val Acc: 0.6484\n",
      "GPU Memory: 0.21GB / 42.47GB\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "Training: 100%|██████████| 32/32 [00:25<00:00,  1.27it/s]\n",
      "Validating: 100%|██████████| 8/8 [00:00<00:00, 67.50it/s]\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Epoch 4, Train Loss: 0.9422, Train Acc: 0.6211, Val Loss: 0.8178, Val Acc: 0.6641\n",
      "GPU Memory: 0.21GB / 42.47GB\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "Training: 100%|██████████| 32/32 [00:20<00:00,  1.53it/s]\n",
      "Validating: 100%|██████████| 8/8 [00:00<00:00, 59.08it/s]\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Epoch 5, Train Loss: 0.9010, Train Acc: 0.6172, Val Loss: 0.6892, Val Acc: 0.7812\n",
      "GPU Memory: 0.21GB / 42.47GB\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "Training: 100%|██████████| 32/32 [00:17<00:00,  1.84it/s]\n",
      "Validating: 100%|██████████| 8/8 [00:00<00:00, 51.43it/s]\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Epoch 6, Train Loss: 0.8385, Train Acc: 0.6562, Val Loss: 0.6262, Val Acc: 0.8125\n",
      "GPU Memory: 0.21GB / 42.47GB\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "Training: 100%|██████████| 32/32 [00:18<00:00,  1.78it/s]\n",
      "Validating: 100%|██████████| 8/8 [00:00<00:00, 50.99it/s]\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Epoch 7, Train Loss: 0.8382, Train Acc: 0.6328, Val Loss: 0.6625, Val Acc: 0.7109\n",
      "GPU Memory: 0.21GB / 42.47GB\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "Training: 100%|██████████| 32/32 [00:16<00:00,  1.94it/s]\n",
      "Validating: 100%|██████████| 8/8 [00:00<00:00, 64.61it/s]\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Epoch 8, Train Loss: 0.7894, Train Acc: 0.6895, Val Loss: 0.5563, Val Acc: 0.8438\n",
      "GPU Memory: 0.21GB / 42.47GB\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "Training: 100%|██████████| 32/32 [00:15<00:00,  2.06it/s]\n",
      "Validating: 100%|██████████| 8/8 [00:00<00:00, 54.57it/s]\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Epoch 9, Train Loss: 0.7347, Train Acc: 0.7031, Val Loss: 0.5652, Val Acc: 0.7734\n",
      "GPU Memory: 0.21GB / 42.47GB\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "Training: 100%|██████████| 32/32 [00:12<00:00,  2.46it/s]\n",
      "Validating: 100%|██████████| 8/8 [00:00<00:00, 54.40it/s]\n",
      "[I 2025-03-20 08:05:30,111] Trial 1 finished with value: 0.84375 and parameters: {'batch_size': 16, 'learning_rate': 0.0004580642847863176, 'dropout_rate': 0.6413325749830208, 'weight_decay': 0.00018848524819375706}. Best is trial 1 with value: 0.84375.\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Epoch 10, Train Loss: 0.7686, Train Acc: 0.6836, Val Loss: 0.7202, Val Acc: 0.6406\n",
      "GPU Memory: 0.21GB / 42.47GB\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "<ipython-input-1-7ef836402601>:313: FutureWarning: `torch.cuda.amp.GradScaler(args...)` is deprecated. Please use `torch.amp.GradScaler('cuda', args...)` instead.\n",
      "  scaler = amp.GradScaler()\n",
      "Training:   0%|          | 0/2 [00:00<?, ?it/s]<ipython-input-1-7ef836402601>:230: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with amp.autocast():\n",
      "Training: 100%|██████████| 2/2 [02:07<00:00, 63.57s/it] \n",
      "<ipython-input-1-7ef836402601>:256: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with torch.no_grad(), amp.autocast():\n",
      "Validating: 100%|██████████| 1/1 [01:03<00:00, 63.74s/it]\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Epoch 1, Train Loss: 1.3945, Train Acc: 0.2461, Val Loss: 1.3543, Val Acc: 0.3125\n",
      "GPU Memory: 0.21GB / 42.47GB\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "Training: 100%|██████████| 2/2 [01:08<00:00, 34.00s/it]\n",
      "Validating: 100%|██████████| 1/1 [00:00<00:00,  2.78it/s]\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Epoch 2, Train Loss: 1.3775, Train Acc: 0.3262, Val Loss: 1.3268, Val Acc: 0.3594\n",
      "GPU Memory: 0.21GB / 42.47GB\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "Training: 100%|██████████| 2/2 [00:30<00:00, 15.08s/it]\n",
      "Validating: 100%|██████████| 1/1 [00:00<00:00,  2.96it/s]\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Epoch 3, Train Loss: 1.3510, Train Acc: 0.3828, Val Loss: 1.2923, Val Acc: 0.4141\n",
      "GPU Memory: 0.21GB / 42.47GB\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "Training: 100%|██████████| 2/2 [00:19<00:00,  9.89s/it]\n",
      "Validating: 100%|██████████| 1/1 [00:00<00:00,  2.97it/s]\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Epoch 4, Train Loss: 1.3028, Train Acc: 0.4082, Val Loss: 1.2542, Val Acc: 0.5156\n",
      "GPU Memory: 0.21GB / 42.47GB\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "Training: 100%|██████████| 2/2 [00:09<00:00,  4.76s/it]\n",
      "Validating: 100%|██████████| 1/1 [00:00<00:00,  3.03it/s]\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Epoch 5, Train Loss: 1.2778, Train Acc: 0.4414, Val Loss: 1.2220, Val Acc: 0.5938\n",
      "GPU Memory: 0.21GB / 42.47GB\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "Training: 100%|██████████| 2/2 [00:06<00:00,  3.07s/it]\n",
      "Validating: 100%|██████████| 1/1 [00:00<00:00,  3.04it/s]\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Epoch 6, Train Loss: 1.2702, Train Acc: 0.4180, Val Loss: 1.1940, Val Acc: 0.5938\n",
      "GPU Memory: 0.21GB / 42.47GB\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "Training: 100%|██████████| 2/2 [00:04<00:00,  2.04s/it]\n",
      "Validating: 100%|██████████| 1/1 [00:00<00:00,  3.02it/s]\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Epoch 7, Train Loss: 1.2385, Train Acc: 0.4727, Val Loss: 1.1693, Val Acc: 0.6406\n",
      "GPU Memory: 0.21GB / 42.47GB\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "Training: 100%|██████████| 2/2 [00:02<00:00,  1.14s/it]\n",
      "Validating: 100%|██████████| 1/1 [00:00<00:00,  3.01it/s]\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Epoch 8, Train Loss: 1.2166, Train Acc: 0.4980, Val Loss: 1.1465, Val Acc: 0.6562\n",
      "GPU Memory: 0.21GB / 42.47GB\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "Training: 100%|██████████| 2/2 [00:02<00:00,  1.10s/it]\n",
      "Validating: 100%|██████████| 1/1 [00:00<00:00,  3.07it/s]\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Epoch 9, Train Loss: 1.1815, Train Acc: 0.5469, Val Loss: 1.1235, Val Acc: 0.7188\n",
      "GPU Memory: 0.21GB / 42.47GB\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "Training: 100%|██████████| 2/2 [00:01<00:00,  1.14it/s]\n",
      "Validating: 100%|██████████| 1/1 [00:00<00:00,  3.05it/s]\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Epoch 10, Train Loss: 1.1708, Train Acc: 0.5664, Val Loss: 1.1031, Val Acc: 0.7422\n",
      "GPU Memory: 0.21GB / 42.47GB\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "[I 2025-03-20 08:11:10,526] Trial 2 finished with value: 0.7421875 and parameters: {'batch_size': 256, 'learning_rate': 0.00019322171971864754, 'dropout_rate': 0.3281322980598389, 'weight_decay': 0.00010565500082882864}. Best is trial 1 with value: 0.84375.\n",
      "<ipython-input-1-7ef836402601>:313: FutureWarning: `torch.cuda.amp.GradScaler(args...)` is deprecated. Please use `torch.amp.GradScaler('cuda', args...)` instead.\n",
      "  scaler = amp.GradScaler()\n",
      "Training:   0%|          | 0/32 [00:00<?, ?it/s]<ipython-input-1-7ef836402601>:230: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with amp.autocast():\n",
      "Training: 100%|██████████| 32/32 [00:31<00:00,  1.00it/s]\n",
      "<ipython-input-1-7ef836402601>:256: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with torch.no_grad(), amp.autocast():\n",
      "Validating: 100%|██████████| 8/8 [00:08<00:00,  1.02s/it]\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Epoch 1, Train Loss: 1.2544, Train Acc: 0.4473, Val Loss: 0.9949, Val Acc: 0.6953\n",
      "GPU Memory: 0.30GB / 42.47GB\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "Training: 100%|██████████| 32/32 [00:29<00:00,  1.09it/s]\n",
      "Validating: 100%|██████████| 8/8 [00:00<00:00, 53.94it/s]\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Epoch 2, Train Loss: 0.9912, Train Acc: 0.6152, Val Loss: 0.7832, Val Acc: 0.7109\n",
      "GPU Memory: 0.30GB / 42.47GB\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "Training: 100%|██████████| 32/32 [00:28<00:00,  1.12it/s]\n",
      "Validating: 100%|██████████| 8/8 [00:00<00:00, 54.20it/s]\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Epoch 3, Train Loss: 0.8203, Train Acc: 0.7090, Val Loss: 0.6519, Val Acc: 0.7500\n",
      "GPU Memory: 0.30GB / 42.47GB\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "Training: 100%|██████████| 32/32 [00:23<00:00,  1.34it/s]\n",
      "Validating: 100%|██████████| 8/8 [00:00<00:00, 62.70it/s]\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Epoch 4, Train Loss: 0.7559, Train Acc: 0.7168, Val Loss: 0.7537, Val Acc: 0.6406\n",
      "GPU Memory: 0.30GB / 42.47GB\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "Training: 100%|██████████| 32/32 [00:21<00:00,  1.46it/s]\n",
      "Validating: 100%|██████████| 8/8 [00:00<00:00, 56.86it/s]\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Epoch 5, Train Loss: 0.6581, Train Acc: 0.7676, Val Loss: 0.6809, Val Acc: 0.6719\n",
      "GPU Memory: 0.30GB / 42.47GB\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "Training: 100%|██████████| 32/32 [00:19<00:00,  1.61it/s]\n",
      "Validating: 100%|██████████| 8/8 [00:00<00:00, 59.01it/s]\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Epoch 6, Train Loss: 0.6483, Train Acc: 0.7559, Val Loss: 0.5445, Val Acc: 0.7812\n",
      "GPU Memory: 0.30GB / 42.47GB\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "Training: 100%|██████████| 32/32 [00:16<00:00,  2.00it/s]\n",
      "Validating: 100%|██████████| 8/8 [00:00<00:00, 50.87it/s]\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Epoch 7, Train Loss: 0.6207, Train Acc: 0.7578, Val Loss: 0.5465, Val Acc: 0.7734\n",
      "GPU Memory: 0.30GB / 42.47GB\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "Training: 100%|██████████| 32/32 [00:15<00:00,  2.07it/s]\n",
      "Validating: 100%|██████████| 8/8 [00:00<00:00, 57.72it/s]\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Epoch 8, Train Loss: 0.5611, Train Acc: 0.8027, Val Loss: 0.5662, Val Acc: 0.7422\n",
      "GPU Memory: 0.30GB / 42.47GB\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "Training: 100%|██████████| 32/32 [00:13<00:00,  2.36it/s]\n",
      "Validating: 100%|██████████| 8/8 [00:00<00:00, 53.96it/s]\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Epoch 9, Train Loss: 0.5243, Train Acc: 0.8086, Val Loss: 0.3901, Val Acc: 0.9062\n",
      "GPU Memory: 0.30GB / 42.47GB\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "Training: 100%|██████████| 32/32 [00:10<00:00,  3.03it/s]\n",
      "Validating: 100%|██████████| 8/8 [00:00<00:00, 53.69it/s]\n",
      "[I 2025-03-20 08:14:52,864] Trial 3 finished with value: 0.90625 and parameters: {'batch_size': 16, 'learning_rate': 0.0006533107679742453, 'dropout_rate': 0.2882558976478706, 'weight_decay': 0.0008734298464935649}. Best is trial 3 with value: 0.90625.\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Epoch 10, Train Loss: 0.5827, Train Acc: 0.7656, Val Loss: 0.3615, Val Acc: 0.8984\n",
      "GPU Memory: 0.30GB / 42.47GB\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "<ipython-input-1-7ef836402601>:313: FutureWarning: `torch.cuda.amp.GradScaler(args...)` is deprecated. Please use `torch.amp.GradScaler('cuda', args...)` instead.\n",
      "  scaler = amp.GradScaler()\n",
      "Training:   0%|          | 0/8 [00:00<?, ?it/s]<ipython-input-1-7ef836402601>:230: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with amp.autocast():\n",
      "Training: 100%|██████████| 8/8 [00:32<00:00,  4.00s/it]\n",
      "<ipython-input-1-7ef836402601>:256: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with torch.no_grad(), amp.autocast():\n",
      "Validating: 100%|██████████| 2/2 [00:33<00:00, 16.57s/it]\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Epoch 1, Train Loss: 1.3849, Train Acc: 0.3105, Val Loss: 1.2198, Val Acc: 0.5000\n",
      "GPU Memory: 0.30GB / 42.47GB\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "Training:  12%|█▎        | 1/8 [00:29<03:24, 29.20s/it]"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Error loading image from https://applied-ai.gr/projects/agriculture/Corn/100/healthy/healthy-478.JPG: HTTPSConnectionPool(host='applied-ai.gr', port=443): Max retries exceeded with url: /projects/agriculture/Corn/100/healthy/healthy-478.JPG (Caused by ConnectTimeoutError(<urllib3.connection.HTTPSConnection object at 0x7d6df23f7b90>, 'Connection to applied-ai.gr timed out. (connect timeout=None)'))\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "Training: 100%|██████████| 8/8 [02:39<00:00, 19.97s/it]\n",
      "Validating: 100%|██████████| 2/2 [00:00<00:00, 10.01it/s]\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Epoch 2, Train Loss: 1.2832, Train Acc: 0.4102, Val Loss: 1.1087, Val Acc: 0.6094\n",
      "GPU Memory: 0.30GB / 42.47GB\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "Training: 100%|██████████| 8/8 [00:25<00:00,  3.23s/it]\n",
      "Validating: 100%|██████████| 2/2 [00:00<00:00,  9.78it/s]\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Epoch 3, Train Loss: 1.1927, Train Acc: 0.4727, Val Loss: 1.0379, Val Acc: 0.6094\n",
      "GPU Memory: 0.30GB / 42.47GB\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "Training: 100%|██████████| 8/8 [00:23<00:00,  2.98s/it]\n",
      "Validating: 100%|██████████| 2/2 [00:00<00:00, 10.71it/s]\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Epoch 4, Train Loss: 1.0982, Train Acc: 0.5293, Val Loss: 0.9602, Val Acc: 0.6797\n",
      "GPU Memory: 0.30GB / 42.47GB\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "Training: 100%|██████████| 8/8 [00:22<00:00,  2.80s/it]\n",
      "Validating: 100%|██████████| 2/2 [00:00<00:00,  9.70it/s]\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Epoch 5, Train Loss: 1.0334, Train Acc: 0.6074, Val Loss: 0.8841, Val Acc: 0.7031\n",
      "GPU Memory: 0.30GB / 42.47GB\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "Training: 100%|██████████| 8/8 [00:19<00:00,  2.43s/it]\n",
      "Validating: 100%|██████████| 2/2 [00:00<00:00,  9.89it/s]\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Epoch 6, Train Loss: 0.9699, Train Acc: 0.6367, Val Loss: 0.8593, Val Acc: 0.6719\n",
      "GPU Memory: 0.30GB / 42.47GB\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "Training: 100%|██████████| 8/8 [00:19<00:00,  2.43s/it]\n",
      "Validating: 100%|██████████| 2/2 [00:00<00:00, 10.93it/s]\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Epoch 7, Train Loss: 0.9095, Train Acc: 0.6602, Val Loss: 0.8073, Val Acc: 0.7109\n",
      "GPU Memory: 0.30GB / 42.47GB\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "Training: 100%|██████████| 8/8 [00:15<00:00,  1.94s/it]\n",
      "Validating: 100%|██████████| 2/2 [00:00<00:00, 10.71it/s]\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Epoch 8, Train Loss: 0.8819, Train Acc: 0.6875, Val Loss: 0.7787, Val Acc: 0.7109\n",
      "GPU Memory: 0.30GB / 42.47GB\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "Training: 100%|██████████| 8/8 [00:12<00:00,  1.51s/it]\n",
      "Validating: 100%|██████████| 2/2 [00:00<00:00,  9.88it/s]\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Epoch 9, Train Loss: 0.8697, Train Acc: 0.6289, Val Loss: 0.7273, Val Acc: 0.7578\n",
      "GPU Memory: 0.30GB / 42.47GB\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "Training: 100%|██████████| 8/8 [00:11<00:00,  1.45s/it]\n",
      "Validating: 100%|██████████| 2/2 [00:00<00:00,  9.89it/s]\n",
      "[I 2025-03-20 08:21:11,827] Trial 4 finished with value: 0.7578125 and parameters: {'batch_size': 64, 'learning_rate': 0.00043257083495812636, 'dropout_rate': 0.649973669068153, 'weight_decay': 0.0002370544392517905}. Best is trial 3 with value: 0.90625.\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Epoch 10, Train Loss: 0.8054, Train Acc: 0.7031, Val Loss: 0.7369, Val Acc: 0.7188\n",
      "GPU Memory: 0.30GB / 42.47GB\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "<ipython-input-1-7ef836402601>:313: FutureWarning: `torch.cuda.amp.GradScaler(args...)` is deprecated. Please use `torch.amp.GradScaler('cuda', args...)` instead.\n",
      "  scaler = amp.GradScaler()\n",
      "Training:   0%|          | 0/2 [00:00<?, ?it/s]<ipython-input-1-7ef836402601>:230: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with amp.autocast():\n",
      "Training: 100%|██████████| 2/2 [02:06<00:00, 63.46s/it] \n",
      "<ipython-input-1-7ef836402601>:256: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with torch.no_grad(), amp.autocast():\n",
      "Validating: 100%|██████████| 1/1 [01:03<00:00, 63.30s/it]\n",
      "[I 2025-03-20 08:24:22,567] Trial 5 pruned. \n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Epoch 1, Train Loss: 1.5056, Train Acc: 0.2168, Val Loss: 1.4500, Val Acc: 0.2188\n",
      "GPU Memory: 0.30GB / 42.47GB\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "<ipython-input-1-7ef836402601>:313: FutureWarning: `torch.cuda.amp.GradScaler(args...)` is deprecated. Please use `torch.amp.GradScaler('cuda', args...)` instead.\n",
      "  scaler = amp.GradScaler()\n",
      "Training:   0%|          | 0/4 [00:00<?, ?it/s]<ipython-input-1-7ef836402601>:230: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with amp.autocast():\n",
      "Training: 100%|██████████| 4/4 [01:03<00:00, 15.96s/it]\n",
      "<ipython-input-1-7ef836402601>:256: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with torch.no_grad(), amp.autocast():\n",
      "Validating: 100%|██████████| 1/1 [01:05<00:00, 65.32s/it]\n",
      "[I 2025-03-20 08:26:32,342] Trial 6 pruned. \n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Epoch 1, Train Loss: 1.4134, Train Acc: 0.2734, Val Loss: 1.3113, Val Acc: 0.3828\n",
      "GPU Memory: 0.30GB / 42.47GB\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "<ipython-input-1-7ef836402601>:313: FutureWarning: `torch.cuda.amp.GradScaler(args...)` is deprecated. Please use `torch.amp.GradScaler('cuda', args...)` instead.\n",
      "  scaler = amp.GradScaler()\n",
      "Training:   0%|          | 0/4 [00:00<?, ?it/s]<ipython-input-1-7ef836402601>:230: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with amp.autocast():\n",
      "Training: 100%|██████████| 4/4 [01:03<00:00, 15.93s/it]\n",
      "<ipython-input-1-7ef836402601>:256: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with torch.no_grad(), amp.autocast():\n",
      "Validating: 100%|██████████| 1/1 [01:03<00:00, 63.43s/it]\n",
      "[I 2025-03-20 08:28:40,098] Trial 7 pruned. \n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Epoch 1, Train Loss: 1.4147, Train Acc: 0.2520, Val Loss: 1.3187, Val Acc: 0.3281\n",
      "GPU Memory: 0.30GB / 42.47GB\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "<ipython-input-1-7ef836402601>:313: FutureWarning: `torch.cuda.amp.GradScaler(args...)` is deprecated. Please use `torch.amp.GradScaler('cuda', args...)` instead.\n",
      "  scaler = amp.GradScaler()\n",
      "Training:   0%|          | 0/32 [00:00<?, ?it/s]<ipython-input-1-7ef836402601>:230: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with amp.autocast():\n",
      "Training: 100%|██████████| 32/32 [00:31<00:00,  1.00it/s]\n",
      "<ipython-input-1-7ef836402601>:256: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with torch.no_grad(), amp.autocast():\n",
      "Validating: 100%|██████████| 8/8 [00:08<00:00,  1.02s/it]\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Epoch 1, Train Loss: 1.2956, Train Acc: 0.3828, Val Loss: 1.1224, Val Acc: 0.6641\n",
      "GPU Memory: 0.30GB / 42.47GB\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "Training: 100%|██████████| 32/32 [00:30<00:00,  1.04it/s]\n",
      "Validating: 100%|██████████| 8/8 [00:00<00:00, 56.04it/s]\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Epoch 2, Train Loss: 1.1233, Train Acc: 0.5391, Val Loss: 0.9485, Val Acc: 0.7266\n",
      "GPU Memory: 0.30GB / 42.47GB\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "Training: 100%|██████████| 32/32 [00:28<00:00,  1.13it/s]\n",
      "Validating: 100%|██████████| 8/8 [00:00<00:00, 55.08it/s]\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Epoch 3, Train Loss: 0.9693, Train Acc: 0.6230, Val Loss: 0.8263, Val Acc: 0.7578\n",
      "GPU Memory: 0.30GB / 42.47GB\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "Training: 100%|██████████| 32/32 [00:21<00:00,  1.46it/s]\n",
      "Validating: 100%|██████████| 8/8 [00:00<00:00, 67.22it/s]\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Epoch 4, Train Loss: 0.9433, Train Acc: 0.6172, Val Loss: 0.8505, Val Acc: 0.5703\n",
      "GPU Memory: 0.30GB / 42.47GB\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "Training: 100%|██████████| 32/32 [00:20<00:00,  1.56it/s]\n",
      "Validating: 100%|██████████| 8/8 [00:00<00:00, 54.72it/s]\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Epoch 5, Train Loss: 0.8204, Train Acc: 0.6934, Val Loss: 0.6992, Val Acc: 0.7812\n",
      "GPU Memory: 0.30GB / 42.47GB\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "Training: 100%|██████████| 32/32 [00:21<00:00,  1.49it/s]\n",
      "Validating: 100%|██████████| 8/8 [00:00<00:00, 63.39it/s]\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Epoch 6, Train Loss: 0.7999, Train Acc: 0.6953, Val Loss: 0.6508, Val Acc: 0.8438\n",
      "GPU Memory: 0.30GB / 42.47GB\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "Training: 100%|██████████| 32/32 [00:17<00:00,  1.83it/s]\n",
      "Validating: 100%|██████████| 8/8 [00:00<00:00, 54.40it/s]\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Epoch 7, Train Loss: 0.7388, Train Acc: 0.7383, Val Loss: 0.6638, Val Acc: 0.7422\n",
      "GPU Memory: 0.30GB / 42.47GB\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "Training: 100%|██████████| 32/32 [00:15<00:00,  2.13it/s]\n",
      "Validating: 100%|██████████| 8/8 [00:00<00:00, 58.90it/s]\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Epoch 8, Train Loss: 0.7213, Train Acc: 0.7285, Val Loss: 0.5825, Val Acc: 0.7891\n",
      "GPU Memory: 0.30GB / 42.47GB\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "Training: 100%|██████████| 32/32 [00:14<00:00,  2.27it/s]\n",
      "Validating: 100%|██████████| 8/8 [00:00<00:00, 57.12it/s]\n",
      "[I 2025-03-20 08:32:12,549] Trial 8 finished with value: 0.84375 and parameters: {'batch_size': 16, 'learning_rate': 0.00037260354591748835, 'dropout_rate': 0.40669360664096776, 'weight_decay': 0.0005759699989525711}. Best is trial 3 with value: 0.90625.\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Epoch 9, Train Loss: 0.7062, Train Acc: 0.7500, Val Loss: 0.6382, Val Acc: 0.7109\n",
      "GPU Memory: 0.30GB / 42.47GB\n",
      "Early stopping at epoch 9\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "<ipython-input-1-7ef836402601>:313: FutureWarning: `torch.cuda.amp.GradScaler(args...)` is deprecated. Please use `torch.amp.GradScaler('cuda', args...)` instead.\n",
      "  scaler = amp.GradScaler()\n",
      "Training:   0%|          | 0/8 [00:00<?, ?it/s]<ipython-input-1-7ef836402601>:230: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with amp.autocast():\n",
      "Training: 100%|██████████| 8/8 [00:32<00:00,  4.02s/it]\n",
      "<ipython-input-1-7ef836402601>:256: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with torch.no_grad(), amp.autocast():\n",
      "Validating: 100%|██████████| 2/2 [00:31<00:00, 15.92s/it]\n",
      "[I 2025-03-20 08:33:17,013] Trial 9 pruned. \n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Epoch 1, Train Loss: 1.4744, Train Acc: 0.2637, Val Loss: 1.4385, Val Acc: 0.2109\n",
      "GPU Memory: 0.40GB / 42.47GB\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "<ipython-input-1-7ef836402601>:313: FutureWarning: `torch.cuda.amp.GradScaler(args...)` is deprecated. Please use `torch.amp.GradScaler('cuda', args...)` instead.\n",
      "  scaler = amp.GradScaler()\n",
      "Training:   0%|          | 0/16 [00:00<?, ?it/s]<ipython-input-1-7ef836402601>:230: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with amp.autocast():\n",
      "Training: 100%|██████████| 16/16 [00:31<00:00,  2.00s/it]\n",
      "<ipython-input-1-7ef836402601>:256: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with torch.no_grad(), amp.autocast():\n",
      "Validating: 100%|██████████| 4/4 [00:16<00:00,  4.03s/it]\n",
      "[I 2025-03-20 08:34:05,687] Trial 10 pruned. \n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Epoch 1, Train Loss: 1.4290, Train Acc: 0.2109, Val Loss: 1.3175, Val Acc: 0.4766\n",
      "GPU Memory: 0.40GB / 42.47GB\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "<ipython-input-1-7ef836402601>:313: FutureWarning: `torch.cuda.amp.GradScaler(args...)` is deprecated. Please use `torch.amp.GradScaler('cuda', args...)` instead.\n",
      "  scaler = amp.GradScaler()\n",
      "Training:   0%|          | 0/32 [00:00<?, ?it/s]<ipython-input-1-7ef836402601>:230: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with amp.autocast():\n",
      "Training: 100%|██████████| 32/32 [00:31<00:00,  1.00it/s]\n",
      "<ipython-input-1-7ef836402601>:256: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with torch.no_grad(), amp.autocast():\n",
      "Validating: 100%|██████████| 8/8 [00:08<00:00,  1.03s/it]\n",
      "[I 2025-03-20 08:34:46,465] Trial 11 pruned. \n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Epoch 1, Train Loss: 1.2875, Train Acc: 0.3906, Val Loss: 1.2188, Val Acc: 0.4609\n",
      "GPU Memory: 0.40GB / 42.47GB\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "<ipython-input-1-7ef836402601>:313: FutureWarning: `torch.cuda.amp.GradScaler(args...)` is deprecated. Please use `torch.amp.GradScaler('cuda', args...)` instead.\n",
      "  scaler = amp.GradScaler()\n",
      "Training:   0%|          | 0/32 [00:00<?, ?it/s]<ipython-input-1-7ef836402601>:230: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with amp.autocast():\n",
      "Training: 100%|██████████| 32/32 [00:33<00:00,  1.03s/it]\n",
      "<ipython-input-1-7ef836402601>:256: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with torch.no_grad(), amp.autocast():\n",
      "Validating: 100%|██████████| 8/8 [00:08<00:00,  1.02s/it]\n",
      "[I 2025-03-20 08:35:28,371] Trial 12 pruned. \n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Epoch 1, Train Loss: 1.4036, Train Acc: 0.2949, Val Loss: 1.3340, Val Acc: 0.3281\n",
      "GPU Memory: 0.40GB / 42.47GB\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "<ipython-input-1-7ef836402601>:313: FutureWarning: `torch.cuda.amp.GradScaler(args...)` is deprecated. Please use `torch.amp.GradScaler('cuda', args...)` instead.\n",
      "  scaler = amp.GradScaler()\n",
      "Training:   0%|          | 0/32 [00:00<?, ?it/s]<ipython-input-1-7ef836402601>:230: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with amp.autocast():\n",
      "Training: 100%|██████████| 32/32 [00:31<00:00,  1.00it/s]\n",
      "<ipython-input-1-7ef836402601>:256: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with torch.no_grad(), amp.autocast():\n",
      "Validating: 100%|██████████| 8/8 [00:08<00:00,  1.04s/it]\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Epoch 1, Train Loss: 1.1935, Train Acc: 0.4727, Val Loss: 0.9078, Val Acc: 0.6016\n",
      "GPU Memory: 0.40GB / 42.47GB\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "Training: 100%|██████████| 32/32 [00:28<00:00,  1.11it/s]\n",
      "Validating: 100%|██████████| 8/8 [00:00<00:00, 60.29it/s]\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Epoch 2, Train Loss: 0.9368, Train Acc: 0.6309, Val Loss: 0.7211, Val Acc: 0.7266\n",
      "GPU Memory: 0.40GB / 42.47GB\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "Training: 100%|██████████| 32/32 [00:26<00:00,  1.19it/s]\n",
      "Validating: 100%|██████████| 8/8 [00:00<00:00, 56.60it/s]\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Epoch 3, Train Loss: 0.8166, Train Acc: 0.6777, Val Loss: 0.6012, Val Acc: 0.7656\n",
      "GPU Memory: 0.40GB / 42.47GB\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "Training: 100%|██████████| 32/32 [00:23<00:00,  1.34it/s]\n",
      "Validating: 100%|██████████| 8/8 [00:00<00:00, 63.20it/s]\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Epoch 4, Train Loss: 0.7401, Train Acc: 0.7129, Val Loss: 0.5347, Val Acc: 0.8047\n",
      "GPU Memory: 0.40GB / 42.47GB\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "Training: 100%|██████████| 32/32 [00:22<00:00,  1.40it/s]\n",
      "Validating: 100%|██████████| 8/8 [00:00<00:00, 58.03it/s]\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Epoch 5, Train Loss: 0.7325, Train Acc: 0.7051, Val Loss: 0.4745, Val Acc: 0.8047\n",
      "GPU Memory: 0.40GB / 42.47GB\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "Training: 100%|██████████| 32/32 [00:18<00:00,  1.69it/s]\n",
      "Validating: 100%|██████████| 8/8 [00:00<00:00, 60.03it/s]\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Epoch 6, Train Loss: 0.6444, Train Acc: 0.7578, Val Loss: 0.6078, Val Acc: 0.7578\n",
      "GPU Memory: 0.40GB / 42.47GB\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "Training: 100%|██████████| 32/32 [00:16<00:00,  1.94it/s]\n",
      "Validating: 100%|██████████| 8/8 [00:00<00:00, 51.86it/s]\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Epoch 7, Train Loss: 0.6884, Train Acc: 0.7168, Val Loss: 0.4094, Val Acc: 0.8594\n",
      "GPU Memory: 0.40GB / 42.47GB\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "Training: 100%|██████████| 32/32 [00:15<00:00,  2.06it/s]\n",
      "Validating: 100%|██████████| 8/8 [00:00<00:00, 58.59it/s]\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Epoch 8, Train Loss: 0.6707, Train Acc: 0.7246, Val Loss: 0.4247, Val Acc: 0.8203\n",
      "GPU Memory: 0.40GB / 42.47GB\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "Training: 100%|██████████| 32/32 [00:12<00:00,  2.54it/s]\n",
      "Validating: 100%|██████████| 8/8 [00:00<00:00, 53.55it/s]\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Epoch 9, Train Loss: 0.6366, Train Acc: 0.7324, Val Loss: 0.3881, Val Acc: 0.8516\n",
      "GPU Memory: 0.40GB / 42.47GB\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "Training: 100%|██████████| 32/32 [00:12<00:00,  2.65it/s]\n",
      "Validating: 100%|██████████| 8/8 [00:00<00:00, 51.89it/s]\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Epoch 10, Train Loss: 0.6861, Train Acc: 0.7480, Val Loss: 0.3520, Val Acc: 0.8672\n",
      "GPU Memory: 0.40GB / 42.47GB\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "[I 2025-03-20 08:39:09,970] Trial 13 finished with value: 0.8671875 and parameters: {'batch_size': 16, 'learning_rate': 0.0009516921585402585, 'dropout_rate': 0.5158931649499858, 'weight_decay': 0.00012320364925506205}. Best is trial 3 with value: 0.90625.\n",
      "<ipython-input-1-7ef836402601>:313: FutureWarning: `torch.cuda.amp.GradScaler(args...)` is deprecated. Please use `torch.amp.GradScaler('cuda', args...)` instead.\n",
      "  scaler = amp.GradScaler()\n",
      "Training:   0%|          | 0/32 [00:00<?, ?it/s]<ipython-input-1-7ef836402601>:230: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with amp.autocast():\n",
      "Training: 100%|██████████| 32/32 [00:31<00:00,  1.00it/s]\n",
      "<ipython-input-1-7ef836402601>:256: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with torch.no_grad(), amp.autocast():\n",
      "Validating: 100%|██████████| 8/8 [00:08<00:00,  1.02s/it]\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Epoch 1, Train Loss: 1.2630, Train Acc: 0.4531, Val Loss: 0.9343, Val Acc: 0.7344\n",
      "GPU Memory: 0.49GB / 42.47GB\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "Training: 100%|██████████| 32/32 [00:30<00:00,  1.06it/s]\n",
      "Validating: 100%|██████████| 8/8 [00:00<00:00, 52.74it/s]\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Epoch 2, Train Loss: 0.9538, Train Acc: 0.6172, Val Loss: 0.9413, Val Acc: 0.6016\n",
      "GPU Memory: 0.49GB / 42.47GB\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "Training: 100%|██████████| 32/32 [00:28<00:00,  1.12it/s]\n",
      "Validating: 100%|██████████| 8/8 [00:00<00:00, 63.07it/s]\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Epoch 3, Train Loss: 0.8858, Train Acc: 0.6445, Val Loss: 0.7387, Val Acc: 0.6875\n",
      "GPU Memory: 0.49GB / 42.47GB\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "Training: 100%|██████████| 32/32 [00:21<00:00,  1.46it/s]\n",
      "Validating: 100%|██████████| 8/8 [00:00<00:00, 54.60it/s]\n",
      "[I 2025-03-20 08:41:11,944] Trial 14 finished with value: 0.734375 and parameters: {'batch_size': 16, 'learning_rate': 0.0009087491896582597, 'dropout_rate': 0.5369656613177378, 'weight_decay': 7.971256778756008e-05}. Best is trial 3 with value: 0.90625.\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Epoch 4, Train Loss: 0.7599, Train Acc: 0.6953, Val Loss: 0.7515, Val Acc: 0.6172\n",
      "GPU Memory: 0.49GB / 42.47GB\n",
      "Early stopping at epoch 4\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "<ipython-input-1-7ef836402601>:313: FutureWarning: `torch.cuda.amp.GradScaler(args...)` is deprecated. Please use `torch.amp.GradScaler('cuda', args...)` instead.\n",
      "  scaler = amp.GradScaler()\n",
      "Training:   0%|          | 0/16 [00:00<?, ?it/s]<ipython-input-1-7ef836402601>:230: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with amp.autocast():\n",
      "Training: 100%|██████████| 16/16 [00:31<00:00,  2.00s/it]\n",
      "<ipython-input-1-7ef836402601>:256: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with torch.no_grad(), amp.autocast():\n",
      "Validating: 100%|██████████| 4/4 [00:16<00:00,  4.00s/it]\n",
      "[I 2025-03-20 08:42:00,450] Trial 15 pruned. \n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Epoch 1, Train Loss: 1.3830, Train Acc: 0.2988, Val Loss: 1.3586, Val Acc: 0.3203\n",
      "GPU Memory: 0.59GB / 42.47GB\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "<ipython-input-1-7ef836402601>:313: FutureWarning: `torch.cuda.amp.GradScaler(args...)` is deprecated. Please use `torch.amp.GradScaler('cuda', args...)` instead.\n",
      "  scaler = amp.GradScaler()\n",
      "Training:   0%|          | 0/32 [00:00<?, ?it/s]<ipython-input-1-7ef836402601>:230: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with amp.autocast():\n",
      "Training: 100%|██████████| 32/32 [00:32<00:00,  1.00s/it]\n",
      "<ipython-input-1-7ef836402601>:256: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with torch.no_grad(), amp.autocast():\n",
      "Validating: 100%|██████████| 8/8 [00:08<00:00,  1.02s/it]\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Epoch 1, Train Loss: 1.2473, Train Acc: 0.4414, Val Loss: 0.9626, Val Acc: 0.7422\n",
      "GPU Memory: 0.49GB / 42.47GB\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "Training: 100%|██████████| 32/32 [00:29<00:00,  1.09it/s]\n",
      "Validating: 100%|██████████| 8/8 [00:00<00:00, 58.36it/s]\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Epoch 2, Train Loss: 0.9353, Train Acc: 0.6172, Val Loss: 0.8142, Val Acc: 0.6406\n",
      "GPU Memory: 0.49GB / 42.47GB\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "Training: 100%|██████████| 32/32 [00:25<00:00,  1.26it/s]\n",
      "Validating: 100%|██████████| 8/8 [00:00<00:00, 58.69it/s]\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Epoch 3, Train Loss: 0.8206, Train Acc: 0.6797, Val Loss: 0.6740, Val Acc: 0.7344\n",
      "GPU Memory: 0.49GB / 42.47GB\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "Training: 100%|██████████| 32/32 [00:24<00:00,  1.32it/s]\n",
      "Validating: 100%|██████████| 8/8 [00:00<00:00, 53.91it/s]\n",
      "[I 2025-03-20 08:44:00,880] Trial 16 finished with value: 0.7421875 and parameters: {'batch_size': 16, 'learning_rate': 0.0008727077141913012, 'dropout_rate': 0.4693009327467026, 'weight_decay': 3.0795389440438216e-05}. Best is trial 3 with value: 0.90625.\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Epoch 4, Train Loss: 0.7650, Train Acc: 0.6934, Val Loss: 0.6430, Val Acc: 0.7188\n",
      "GPU Memory: 0.49GB / 42.47GB\n",
      "Early stopping at epoch 4\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "<ipython-input-1-7ef836402601>:313: FutureWarning: `torch.cuda.amp.GradScaler(args...)` is deprecated. Please use `torch.amp.GradScaler('cuda', args...)` instead.\n",
      "  scaler = amp.GradScaler()\n",
      "Training:   0%|          | 0/32 [00:00<?, ?it/s]<ipython-input-1-7ef836402601>:230: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with amp.autocast():\n",
      "Training: 100%|██████████| 32/32 [00:31<00:00,  1.00it/s]\n",
      "<ipython-input-1-7ef836402601>:256: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with torch.no_grad(), amp.autocast():\n",
      "Validating: 100%|██████████| 8/8 [00:08<00:00,  1.02s/it]\n",
      "[I 2025-03-20 08:44:41,545] Trial 17 pruned. \n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Epoch 1, Train Loss: 1.3775, Train Acc: 0.3223, Val Loss: 1.2298, Val Acc: 0.4688\n",
      "GPU Memory: 0.49GB / 42.47GB\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "<ipython-input-1-7ef836402601>:313: FutureWarning: `torch.cuda.amp.GradScaler(args...)` is deprecated. Please use `torch.amp.GradScaler('cuda', args...)` instead.\n",
      "  scaler = amp.GradScaler()\n",
      "Training:   0%|          | 0/32 [00:00<?, ?it/s]<ipython-input-1-7ef836402601>:230: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with amp.autocast():\n",
      "Training: 100%|██████████| 32/32 [00:32<00:00,  1.00s/it]\n",
      "<ipython-input-1-7ef836402601>:256: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with torch.no_grad(), amp.autocast():\n",
      "Validating: 100%|██████████| 8/8 [00:08<00:00,  1.02s/it]\n",
      "[I 2025-03-20 08:45:22,445] Trial 18 pruned. \n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Epoch 1, Train Loss: 1.4273, Train Acc: 0.2402, Val Loss: 1.3662, Val Acc: 0.3359\n",
      "GPU Memory: 0.49GB / 42.47GB\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "<ipython-input-1-7ef836402601>:313: FutureWarning: `torch.cuda.amp.GradScaler(args...)` is deprecated. Please use `torch.amp.GradScaler('cuda', args...)` instead.\n",
      "  scaler = amp.GradScaler()\n",
      "Training:   0%|          | 0/16 [00:00<?, ?it/s]<ipython-input-1-7ef836402601>:230: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with amp.autocast():\n",
      "Training: 100%|██████████| 16/16 [00:31<00:00,  2.00s/it]\n",
      "<ipython-input-1-7ef836402601>:256: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with torch.no_grad(), amp.autocast():\n",
      "Validating: 100%|██████████| 4/4 [00:16<00:00,  4.01s/it]\n",
      "[I 2025-03-20 08:46:11,067] Trial 19 pruned. \n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Epoch 1, Train Loss: 1.4508, Train Acc: 0.2500, Val Loss: 1.4719, Val Acc: 0.1250\n",
      "GPU Memory: 0.49GB / 42.47GB\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "<ipython-input-1-7ef836402601>:313: FutureWarning: `torch.cuda.amp.GradScaler(args...)` is deprecated. Please use `torch.amp.GradScaler('cuda', args...)` instead.\n",
      "  scaler = amp.GradScaler()\n",
      "Training:   0%|          | 0/4 [00:00<?, ?it/s]<ipython-input-1-7ef836402601>:230: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with amp.autocast():\n",
      "Training: 100%|██████████| 4/4 [01:03<00:00, 15.92s/it]\n",
      "<ipython-input-1-7ef836402601>:256: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with torch.no_grad(), amp.autocast():\n",
      "Validating: 100%|██████████| 1/1 [01:03<00:00, 63.41s/it]\n",
      "[I 2025-03-20 08:48:18,960] Trial 20 pruned. \n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Epoch 1, Train Loss: 1.5064, Train Acc: 0.2266, Val Loss: 1.3458, Val Acc: 0.3203\n",
      "GPU Memory: 0.11GB / 42.47GB\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "<ipython-input-1-7ef836402601>:313: FutureWarning: `torch.cuda.amp.GradScaler(args...)` is deprecated. Please use `torch.amp.GradScaler('cuda', args...)` instead.\n",
      "  scaler = amp.GradScaler()\n",
      "Training:   0%|          | 0/32 [00:00<?, ?it/s]<ipython-input-1-7ef836402601>:230: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with amp.autocast():\n",
      "Training: 100%|██████████| 32/32 [00:31<00:00,  1.00it/s]\n",
      "<ipython-input-1-7ef836402601>:256: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with torch.no_grad(), amp.autocast():\n",
      "Validating: 100%|██████████| 8/8 [00:08<00:00,  1.02s/it]\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Epoch 1, Train Loss: 1.2531, Train Acc: 0.4180, Val Loss: 0.9948, Val Acc: 0.7266\n",
      "GPU Memory: 0.11GB / 42.47GB\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "Training: 100%|██████████| 32/32 [00:28<00:00,  1.13it/s]\n",
      "Validating: 100%|██████████| 8/8 [00:00<00:00, 54.15it/s]\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Epoch 2, Train Loss: 1.0152, Train Acc: 0.5840, Val Loss: 0.7891, Val Acc: 0.7500\n",
      "GPU Memory: 0.11GB / 42.47GB\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "Training: 100%|██████████| 32/32 [00:26<00:00,  1.19it/s]\n",
      "Validating: 100%|██████████| 8/8 [00:00<00:00, 60.74it/s]\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Epoch 3, Train Loss: 0.8345, Train Acc: 0.7070, Val Loss: 0.6957, Val Acc: 0.7734\n",
      "GPU Memory: 0.11GB / 42.47GB\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "Training: 100%|██████████| 32/32 [00:23<00:00,  1.37it/s]\n",
      "Validating: 100%|██████████| 8/8 [00:00<00:00, 54.45it/s]\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Epoch 4, Train Loss: 0.7437, Train Acc: 0.7363, Val Loss: 0.6631, Val Acc: 0.7344\n",
      "GPU Memory: 0.11GB / 42.47GB\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "Training: 100%|██████████| 32/32 [00:18<00:00,  1.69it/s]\n",
      "Validating: 100%|██████████| 8/8 [00:00<00:00, 51.11it/s]\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Epoch 5, Train Loss: 0.6950, Train Acc: 0.7402, Val Loss: 0.6265, Val Acc: 0.7266\n",
      "GPU Memory: 0.11GB / 42.47GB\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "Training: 100%|██████████| 32/32 [00:18<00:00,  1.73it/s]\n",
      "Validating: 100%|██████████| 8/8 [00:00<00:00, 56.64it/s]\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Epoch 6, Train Loss: 0.6883, Train Acc: 0.7168, Val Loss: 0.5546, Val Acc: 0.7891\n",
      "GPU Memory: 0.11GB / 42.47GB\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "Training: 100%|██████████| 32/32 [00:16<00:00,  1.88it/s]\n",
      "Validating: 100%|██████████| 8/8 [00:00<00:00, 57.63it/s]\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Epoch 7, Train Loss: 0.7253, Train Acc: 0.6953, Val Loss: 0.6811, Val Acc: 0.6484\n",
      "GPU Memory: 0.11GB / 42.47GB\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "Training: 100%|██████████| 32/32 [00:14<00:00,  2.20it/s]\n",
      "Validating: 100%|██████████| 8/8 [00:00<00:00, 51.90it/s]\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Epoch 8, Train Loss: 0.6884, Train Acc: 0.6934, Val Loss: 0.4854, Val Acc: 0.8047\n",
      "GPU Memory: 0.11GB / 42.47GB\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "Training: 100%|██████████| 32/32 [00:13<00:00,  2.43it/s]\n",
      "Validating: 100%|██████████| 8/8 [00:00<00:00, 54.15it/s]\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Epoch 9, Train Loss: 0.6072, Train Acc: 0.7656, Val Loss: 0.4579, Val Acc: 0.8281\n",
      "GPU Memory: 0.11GB / 42.47GB\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "Training: 100%|██████████| 32/32 [00:10<00:00,  3.00it/s]\n",
      "Validating: 100%|██████████| 8/8 [00:00<00:00, 66.07it/s]\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Epoch 10, Train Loss: 0.6256, Train Acc: 0.7637, Val Loss: 0.4019, Val Acc: 0.8750\n",
      "GPU Memory: 0.11GB / 42.47GB\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "[I 2025-03-20 08:51:53,886] Trial 21 finished with value: 0.875 and parameters: {'batch_size': 16, 'learning_rate': 0.0006664481852428999, 'dropout_rate': 0.4877851108860009, 'weight_decay': 0.00017820793087548693}. Best is trial 3 with value: 0.90625.\n",
      "<ipython-input-1-7ef836402601>:313: FutureWarning: `torch.cuda.amp.GradScaler(args...)` is deprecated. Please use `torch.amp.GradScaler('cuda', args...)` instead.\n",
      "  scaler = amp.GradScaler()\n",
      "Training:   0%|          | 0/32 [00:00<?, ?it/s]<ipython-input-1-7ef836402601>:230: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with amp.autocast():\n",
      "Training: 100%|██████████| 32/32 [00:31<00:00,  1.00it/s]\n",
      "<ipython-input-1-7ef836402601>:256: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with torch.no_grad(), amp.autocast():\n",
      "Validating: 100%|██████████| 8/8 [00:08<00:00,  1.02s/it]\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Epoch 1, Train Loss: 1.3446, Train Acc: 0.3711, Val Loss: 0.9154, Val Acc: 0.7812\n",
      "GPU Memory: 0.11GB / 42.47GB\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "Training: 100%|██████████| 32/32 [00:29<00:00,  1.08it/s]\n",
      "Validating: 100%|██████████| 8/8 [00:00<00:00, 59.10it/s]\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Epoch 2, Train Loss: 0.9269, Train Acc: 0.6191, Val Loss: 0.6919, Val Acc: 0.7656\n",
      "GPU Memory: 0.11GB / 42.47GB\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "Training: 100%|██████████| 32/32 [00:25<00:00,  1.24it/s]\n",
      "Validating: 100%|██████████| 8/8 [00:00<00:00, 60.26it/s]\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Epoch 3, Train Loss: 0.8896, Train Acc: 0.6504, Val Loss: 0.6218, Val Acc: 0.7812\n",
      "GPU Memory: 0.11GB / 42.47GB\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "Training: 100%|██████████| 32/32 [00:22<00:00,  1.45it/s]\n",
      "Validating: 100%|██████████| 8/8 [00:00<00:00, 57.64it/s]\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Epoch 4, Train Loss: 0.7445, Train Acc: 0.7168, Val Loss: 0.5453, Val Acc: 0.7969\n",
      "GPU Memory: 0.11GB / 42.47GB\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "Training: 100%|██████████| 32/32 [00:21<00:00,  1.46it/s]\n",
      "Validating: 100%|██████████| 8/8 [00:00<00:00, 66.92it/s]\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Epoch 5, Train Loss: 0.7135, Train Acc: 0.7188, Val Loss: 0.5899, Val Acc: 0.7266\n",
      "GPU Memory: 0.11GB / 42.47GB\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "Training: 100%|██████████| 32/32 [00:17<00:00,  1.83it/s]\n",
      "Validating: 100%|██████████| 8/8 [00:00<00:00, 63.27it/s]\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Epoch 6, Train Loss: 0.6985, Train Acc: 0.7168, Val Loss: 0.4192, Val Acc: 0.8438\n",
      "GPU Memory: 0.11GB / 42.47GB\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "Training: 100%|██████████| 32/32 [00:17<00:00,  1.82it/s]\n",
      "Validating: 100%|██████████| 8/8 [00:00<00:00, 54.79it/s]\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Epoch 7, Train Loss: 0.6042, Train Acc: 0.7852, Val Loss: 0.4601, Val Acc: 0.8359\n",
      "GPU Memory: 0.11GB / 42.47GB\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "Training: 100%|██████████| 32/32 [00:16<00:00,  1.99it/s]\n",
      "Validating: 100%|██████████| 8/8 [00:00<00:00, 64.26it/s]\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Epoch 8, Train Loss: 0.6261, Train Acc: 0.7539, Val Loss: 0.6821, Val Acc: 0.6875\n",
      "GPU Memory: 0.11GB / 42.47GB\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "Training: 100%|██████████| 32/32 [00:13<00:00,  2.44it/s]\n",
      "Validating: 100%|██████████| 8/8 [00:00<00:00, 55.22it/s]\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Epoch 9, Train Loss: 0.6554, Train Acc: 0.7324, Val Loss: 0.3620, Val Acc: 0.8750\n",
      "GPU Memory: 0.11GB / 42.47GB\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "Training: 100%|██████████| 32/32 [00:13<00:00,  2.45it/s]\n",
      "Validating: 100%|██████████| 8/8 [00:00<00:00, 62.34it/s]\n",
      "[I 2025-03-20 08:55:33,490] Trial 22 finished with value: 0.875 and parameters: {'batch_size': 16, 'learning_rate': 0.0009808296778225692, 'dropout_rate': 0.47286763967002937, 'weight_decay': 0.0001415506893763788}. Best is trial 3 with value: 0.90625.\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Epoch 10, Train Loss: 0.6178, Train Acc: 0.7520, Val Loss: 0.4631, Val Acc: 0.7969\n",
      "GPU Memory: 0.11GB / 42.47GB\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "<ipython-input-1-7ef836402601>:313: FutureWarning: `torch.cuda.amp.GradScaler(args...)` is deprecated. Please use `torch.amp.GradScaler('cuda', args...)` instead.\n",
      "  scaler = amp.GradScaler()\n",
      "Training:   0%|          | 0/32 [00:00<?, ?it/s]<ipython-input-1-7ef836402601>:230: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with amp.autocast():\n",
      "Training: 100%|██████████| 32/32 [00:32<00:00,  1.00s/it]\n",
      "<ipython-input-1-7ef836402601>:256: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with torch.no_grad(), amp.autocast():\n",
      "Validating: 100%|██████████| 8/8 [00:08<00:00,  1.04s/it]\n",
      "[I 2025-03-20 08:56:14,342] Trial 23 pruned. \n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Epoch 1, Train Loss: 1.3160, Train Acc: 0.4082, Val Loss: 1.0817, Val Acc: 0.5703\n",
      "GPU Memory: 0.11GB / 42.47GB\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "<ipython-input-1-7ef836402601>:313: FutureWarning: `torch.cuda.amp.GradScaler(args...)` is deprecated. Please use `torch.amp.GradScaler('cuda', args...)` instead.\n",
      "  scaler = amp.GradScaler()\n",
      "Training:   0%|          | 0/32 [00:00<?, ?it/s]<ipython-input-1-7ef836402601>:230: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with amp.autocast():\n",
      "Training: 100%|██████████| 32/32 [00:32<00:00,  1.01s/it]\n",
      "<ipython-input-1-7ef836402601>:256: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with torch.no_grad(), amp.autocast():\n",
      "Validating: 100%|██████████| 8/8 [00:08<00:00,  1.02s/it]\n",
      "[I 2025-03-20 08:56:55,580] Trial 24 pruned. \n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Epoch 1, Train Loss: 1.3878, Train Acc: 0.2832, Val Loss: 1.2233, Val Acc: 0.3906\n",
      "GPU Memory: 0.11GB / 42.47GB\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "<ipython-input-1-7ef836402601>:313: FutureWarning: `torch.cuda.amp.GradScaler(args...)` is deprecated. Please use `torch.amp.GradScaler('cuda', args...)` instead.\n",
      "  scaler = amp.GradScaler()\n",
      "Training:   0%|          | 0/2 [00:00<?, ?it/s]<ipython-input-1-7ef836402601>:230: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with amp.autocast():\n",
      "Training: 100%|██████████| 2/2 [02:07<00:00, 63.78s/it] \n",
      "<ipython-input-1-7ef836402601>:256: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with torch.no_grad(), amp.autocast():\n",
      "Validating: 100%|██████████| 1/1 [01:03<00:00, 63.54s/it]\n",
      "[I 2025-03-20 09:00:07,294] Trial 25 pruned. \n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Epoch 1, Train Loss: 1.4336, Train Acc: 0.2852, Val Loss: 1.3342, Val Acc: 0.4297\n",
      "GPU Memory: 0.11GB / 42.47GB\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "Exception in thread QueueFeederThread:\n",
      "Traceback (most recent call last):\n",
      "  File \"/usr/lib/python3.11/multiprocessing/queues.py\", line 239, in _feed\n",
      "Exception in thread QueueFeederThread:\n",
      "Traceback (most recent call last):\n",
      "  File \"/usr/lib/python3.11/multiprocessing/queues.py\", line 239, in _feed\n",
      "    reader_close()\n",
      "  File \"/usr/lib/python3.11/multiprocessing/connection.py\", line 178, in close\n",
      "Exception in thread QueueFeederThread:\n",
      "Traceback (most recent call last):\n",
      "  File \"/usr/lib/python3.11/multiprocessing/queues.py\", line 239, in _feed\n",
      "    self._close()\n",
      "  File \"/usr/lib/python3.11/multiprocessing/connection.py\", line 377, in _close\n",
      "    _close(self._handle)\n",
      "OSError: [Errno 9] Bad file descriptor\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/usr/lib/python3.11/threading.py\", line 1045, in _bootstrap_inner\n",
      "    reader_close()\n",
      "  File \"/usr/lib/python3.11/multiprocessing/connection.py\", line 178, in close\n",
      "Exception in thread QueueFeederThread:\n",
      "Traceback (most recent call last):\n",
      "  File \"/usr/lib/python3.11/multiprocessing/queues.py\", line 239, in _feed\n",
      "    self.run()\n",
      "  File \"/usr/lib/python3.11/threading.py\", line 982, in run\n",
      "    self._close()\n",
      "  File \"/usr/lib/python3.11/multiprocessing/connection.py\", line 377, in _close\n",
      "    _close(self._handle)\n",
      "OSError: [Errno 9] Bad file descriptor\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/usr/lib/python3.11/threading.py\", line 1045, in _bootstrap_inner\n",
      "    reader_close()\n",
      "  File \"/usr/lib/python3.11/multiprocessing/connection.py\", line 178, in close\n",
      "    self.run()\n",
      "  File \"/usr/lib/python3.11/threading.py\", line 982, in run\n",
      "    reader_close()\n",
      "  File \"/usr/lib/python3.11/multiprocessing/connection.py\", line 178, in close\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/usr/lib/python3.11/multiprocessing/queues.py\", line 271, in _feed\n",
      "    queue_sem.release()\n",
      "ValueError: semaphore or lock released too many times\n",
      "    self._close()\n",
      "  File \"/usr/lib/python3.11/multiprocessing/connection.py\", line 377, in _close\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/usr/lib/python3.11/multiprocessing/queues.py\", line 271, in _feed\n",
      "    queue_sem.release()\n",
      "ValueError: semaphore or lock released too many times\n",
      "        self._close()\n",
      "  File \"/usr/lib/python3.11/multiprocessing/connection.py\", line 377, in _close\n",
      "_close(self._handle)\n",
      "OSError: [Errno 9] Bad file descriptor\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/usr/lib/python3.11/threading.py\", line 1045, in _bootstrap_inner\n",
      "    self.run()\n",
      "  File \"/usr/lib/python3.11/threading.py\", line 982, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/usr/lib/python3.11/multiprocessing/queues.py\", line 271, in _feed\n",
      "    _close(self._handle)\n",
      "OSError: [Errno 9] Bad file descriptor\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/usr/lib/python3.11/threading.py\", line 1045, in _bootstrap_inner\n",
      "    queue_sem.release()\n",
      "ValueError: semaphore or lock released too many times\n",
      "    self.run()\n",
      "  File \"/usr/lib/python3.11/threading.py\", line 982, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/usr/lib/python3.11/multiprocessing/queues.py\", line 271, in _feed\n",
      "    queue_sem.release()\n",
      "ValueError: semaphore or lock released too many times\n",
      "Exception in thread QueueFeederThread:\n",
      "Traceback (most recent call last):\n",
      "  File \"/usr/lib/python3.11/multiprocessing/queues.py\", line 239, in _feed\n",
      "Exception ignored in: <function _ConnectionBase.__del__ at 0x7d6cdb2f9940>\n",
      "Traceback (most recent call last):\n",
      "  File \"/usr/lib/python3.11/multiprocessing/connection.py\", line 133, in __del__\n",
      "    reader_close()\n",
      "  File \"/usr/lib/python3.11/multiprocessing/connection.py\", line 178, in close\n",
      "    self._close()\n",
      "  File \"/usr/lib/python3.11/multiprocessing/connection.py\", line 377, in _close\n",
      "    _close(self._handle)\n",
      "OSError: [Errno 9] Bad file descriptor\n",
      "    self._close()\n",
      "  File \"/usr/lib/python3.11/multiprocessing/connection.py\", line 377, in _close\n",
      "    _close(self._handle)\n",
      "OSError: [Errno 9] Bad file descriptor\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/usr/lib/python3.11/threading.py\", line 1045, in _bootstrap_inner\n",
      "    self.run()\n",
      "  File \"/usr/lib/python3.11/threading.py\", line 982, in run\n",
      "Exception ignored in: <function _ConnectionBase.__del__ at 0x7d6cdb2f9940>\n",
      "Traceback (most recent call last):\n",
      "  File \"/usr/lib/python3.11/multiprocessing/connection.py\", line 133, in __del__\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/usr/lib/python3.11/multiprocessing/queues.py\", line 271, in _feed\n",
      "    self._close()\n",
      "  File \"/usr/lib/python3.11/multiprocessing/connection.py\", line 377, in _close\n",
      "    queue_sem.release()\n",
      "ValueError: semaphore or lock released too many times\n",
      "    _close(self._handle)\n",
      "OSError: [Errno 9] Bad file descriptor\n",
      "<ipython-input-1-7ef836402601>:313: FutureWarning: `torch.cuda.amp.GradScaler(args...)` is deprecated. Please use `torch.amp.GradScaler('cuda', args...)` instead.\n",
      "  scaler = amp.GradScaler()\n",
      "Training:   0%|          | 0/32 [00:00<?, ?it/s]<ipython-input-1-7ef836402601>:230: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with amp.autocast():\n",
      "Training: 100%|██████████| 32/32 [00:31<00:00,  1.00it/s]\n",
      "<ipython-input-1-7ef836402601>:256: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with torch.no_grad(), amp.autocast():\n",
      "Validating: 100%|██████████| 8/8 [00:09<00:00,  1.15s/it]\n",
      "[I 2025-03-20 09:01:03,957] Trial 26 pruned. \n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Epoch 1, Train Loss: 1.3551, Train Acc: 0.3184, Val Loss: 1.2256, Val Acc: 0.5859\n",
      "GPU Memory: 0.11GB / 42.47GB\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "<ipython-input-1-7ef836402601>:313: FutureWarning: `torch.cuda.amp.GradScaler(args...)` is deprecated. Please use `torch.amp.GradScaler('cuda', args...)` instead.\n",
      "  scaler = amp.GradScaler()\n",
      "Training:   0%|          | 0/32 [00:00<?, ?it/s]<ipython-input-1-7ef836402601>:230: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with amp.autocast():\n",
      "Training: 100%|██████████| 32/32 [00:31<00:00,  1.00it/s]\n",
      "<ipython-input-1-7ef836402601>:256: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with torch.no_grad(), amp.autocast():\n",
      "Validating: 100%|██████████| 8/8 [00:08<00:00,  1.03s/it]\n",
      "[I 2025-03-20 09:01:44,786] Trial 27 pruned. \n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Epoch 1, Train Loss: 1.3923, Train Acc: 0.2676, Val Loss: 1.3778, Val Acc: 0.3281\n",
      "GPU Memory: 0.11GB / 42.47GB\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "<ipython-input-1-7ef836402601>:313: FutureWarning: `torch.cuda.amp.GradScaler(args...)` is deprecated. Please use `torch.amp.GradScaler('cuda', args...)` instead.\n",
      "  scaler = amp.GradScaler()\n",
      "Training:   0%|          | 0/32 [00:00<?, ?it/s]<ipython-input-1-7ef836402601>:230: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with amp.autocast():\n",
      "Training: 100%|██████████| 32/32 [00:31<00:00,  1.00it/s]\n",
      "<ipython-input-1-7ef836402601>:256: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with torch.no_grad(), amp.autocast():\n",
      "Validating: 100%|██████████| 8/8 [00:08<00:00,  1.02s/it]\n",
      "[I 2025-03-20 09:02:25,591] Trial 28 pruned. \n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Epoch 1, Train Loss: 1.4233, Train Acc: 0.2969, Val Loss: 1.3361, Val Acc: 0.3594\n",
      "GPU Memory: 0.11GB / 42.47GB\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "<ipython-input-1-7ef836402601>:313: FutureWarning: `torch.cuda.amp.GradScaler(args...)` is deprecated. Please use `torch.amp.GradScaler('cuda', args...)` instead.\n",
      "  scaler = amp.GradScaler()\n",
      "Training:   0%|          | 0/8 [00:00<?, ?it/s]<ipython-input-1-7ef836402601>:230: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with amp.autocast():\n",
      "Training: 100%|██████████| 8/8 [00:32<00:00,  4.00s/it]\n",
      "<ipython-input-1-7ef836402601>:256: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with torch.no_grad(), amp.autocast():\n",
      "Validating: 100%|██████████| 2/2 [00:31<00:00, 15.90s/it]\n",
      "[I 2025-03-20 09:03:30,029] Trial 29 pruned. \n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Epoch 1, Train Loss: 1.4209, Train Acc: 0.2754, Val Loss: 1.3044, Val Acc: 0.4062\n",
      "GPU Memory: 0.11GB / 42.47GB\n",
      "Best trial: 3\n",
      "Best validation accuracy: 0.9062\n",
      "Best hyperparameters: {'batch_size': 16, 'learning_rate': 0.0006533107679742453, 'dropout_rate': 0.2882558976478706, 'weight_decay': 0.0008734298464935649}\n",
      "Best model saved to /content/gdrive/My Drive/Projects/Multimodal/Datasets/corn-best_resnet50_model-100.pth\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "### Overview:\n",
    "This script is designed for training an image classification model using a fine-tuned ResNet-50, incorporating data preprocessing,\n",
    "augmentation, and hyperparameter optimization via Bayesian methods.\n",
    "\n",
    "### Key Steps:\n",
    "\n",
    "1. Label Encoding:\n",
    "   - Converts categorical labels from the dataset into numerical values.\n",
    "   - Saves the mapping dictionary (`label_to_idx.json`) to ensure consistency across datasets.\n",
    "\n",
    "2. Custom Dataset Class (`CornDataset`):\n",
    "   - Loads image paths and their corresponding labels from CSV files.\n",
    "   - Facilitates easy integration with PyTorch’s `DataLoader`.\n",
    "\n",
    "3. Data Augmentation:\n",
    "   - Applies random transformations (cropping, flipping, rotation, color jittering) to the training images.\n",
    "   - Aims to enhance model robustness and reduce overfitting.\n",
    "\n",
    "4. Model Setup (ResNet-50 Fine-tuning):\n",
    "   - Uses a pre-trained ResNet-50 as the feature extractor.\n",
    "   - Unfreezes the last few layers to allow fine-tuning.\n",
    "   - Replaces the final classification layer with a custom fully connected layer, including dropout for regularization.\n",
    "\n",
    "5. Bayesian Optimization (Optuna for Hyperparameter Tuning):\n",
    "   - Searches for the best hyperparameters to maximize validation accuracy.\n",
    "   - Tunable parameters include:\n",
    "     - **Batch size:** {16, 32, 64}\n",
    "     - **Learning rate:** Continuous range from 1e-5 to 1e-3\n",
    "     - **Dropout rate:** Continuous range from 0.2 to 0.7\n",
    "     - **Weight decay:** Continuous range from 1e-5 to 1e-3\n",
    "\n",
    "6. Training Process:\n",
    "   - Each trial runs for a maximum of **10 epochs**.\n",
    "   - Implements **early stopping** to halt training if validation accuracy plateaus.\n",
    "\n",
    "7. Model Selection & Saving:\n",
    "   - The best-performing model from all trials is saved as `best_resnet50_model.pth`.\n",
    "   - Ensures optimal performance on unseen data.\n",
    "\n",
    "This pipeline efficiently optimizes and fine-tunes the ResNet-50 model while leveraging Bayesian optimization for better hyperparameter selection.\n",
    "\"\"\"\n",
    "\n",
    "!pip install torch torchvision pandas pillow scikit-learn optuna tqdm\n",
    "import os\n",
    "import json\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torchvision import models, transforms\n",
    "import pandas as pd\n",
    "from PIL import Image\n",
    "import numpy as np\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "import optuna\n",
    "from optuna.samplers import TPESampler\n",
    "from tqdm import tqdm\n",
    "import requests\n",
    "from io import BytesIO\n",
    "import torch.cuda.amp as amp  # Import for mixed precision training\n",
    "\n",
    "from google.colab import drive\n",
    "drive.mount('/content/gdrive')\n",
    "\n",
    "# Define paths\n",
    "absolute_path = \"/content/gdrive/My Drive/Projects/Multimodal/\"\n",
    "TRAIN_CSV = absolute_path + \"Datasets/Corn_train_set_100.csv\"\n",
    "VAL_CSV = absolute_path + \"Datasets/Corn_validation_set_100.csv\"\n",
    "LABEL_JSON = absolute_path + \"Datasets/corn-label_to_idx-100.json\"\n",
    "BEST_MODEL_PATH = absolute_path + \"Datasets/corn-best_resnet50_model-100.pth\"\n",
    "\n",
    "# Device configuration\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "print(f\"Using device: {device}\")\n",
    "\n",
    "# Print GPU info\n",
    "if torch.cuda.is_available():\n",
    "    print(f\"GPU: {torch.cuda.get_device_name(0)}\")\n",
    "    print(f\"Memory Allocated: {torch.cuda.memory_allocated(0)/1e9:.2f} GB\")\n",
    "    print(f\"Memory Reserved: {torch.cuda.memory_reserved(0)/1e9:.2f} GB\")\n",
    "    print(f\"Total Memory: {torch.cuda.get_device_properties(0).total_memory/1e9:.2f} GB\")\n",
    "\n",
    "BATCH_SIZES = [16, 32, 64, 128, 256]\n",
    "NUM_WORKERS = 8\n",
    "PREFETCH_FACTOR = 2\n",
    "\n",
    "# Set up data prefetching and pinning\n",
    "torch.multiprocessing.set_sharing_strategy('file_system')\n",
    "torch.set_float32_matmul_precision('high')  # Use TF32 precision on A100\n",
    "\n",
    "# Prepare data downloading and caching\n",
    "class ImageCache:\n",
    "    def __init__(self, capacity=1000):\n",
    "        self.capacity = capacity\n",
    "        self.cache = {}\n",
    "\n",
    "    def get(self, url):\n",
    "        if url in self.cache:\n",
    "            return self.cache[url]\n",
    "\n",
    "        try:\n",
    "            response = requests.get(url)\n",
    "            image = Image.open(BytesIO(response.content)).convert('RGB')\n",
    "\n",
    "            # Keep cache size in check\n",
    "            if len(self.cache) >= self.capacity:\n",
    "                # Remove a random item\n",
    "                self.cache.pop(next(iter(self.cache)))\n",
    "\n",
    "            self.cache[url] = image\n",
    "            return image\n",
    "        except Exception as e:\n",
    "            print(f\"Error loading image from {url}: {e}\")\n",
    "            return Image.new('RGB', (224, 224), color='black')\n",
    "\n",
    "# Global image cache\n",
    "image_cache = ImageCache()\n",
    "\n",
    "# Custom Dataset with optimized loading\n",
    "class CornDataset(Dataset):\n",
    "    def __init__(self, csv_file, transform=None):\n",
    "        self.data = pd.read_csv(csv_file)\n",
    "        self.transform = transform\n",
    "\n",
    "        # Load the label encoding\n",
    "        with open(LABEL_JSON, 'r') as f:\n",
    "            self.label_to_idx = json.load(f)\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.data)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        img_url = self.data.iloc[idx]['Image']\n",
    "        category = self.data.iloc[idx]['Category']\n",
    "\n",
    "        # Convert category to encoded label\n",
    "        label = self.label_to_idx[category]\n",
    "\n",
    "        # Load image from URL with caching\n",
    "        image = image_cache.get(img_url)\n",
    "\n",
    "        if self.transform:\n",
    "            image = self.transform(image)\n",
    "\n",
    "        return image, label\n",
    "\n",
    "# Function to create the dataset and dataloaders\n",
    "def create_data_loaders(batch_size):\n",
    "    # Define transformations\n",
    "    train_transform = transforms.Compose([\n",
    "        transforms.RandomResizedCrop(224),\n",
    "        transforms.RandomHorizontalFlip(),\n",
    "        transforms.RandomRotation(15),\n",
    "        transforms.ColorJitter(brightness=0.1, contrast=0.1, saturation=0.1),\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n",
    "    ])\n",
    "\n",
    "    val_transform = transforms.Compose([\n",
    "        transforms.Resize(256),\n",
    "        transforms.CenterCrop(224),\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n",
    "    ])\n",
    "\n",
    "    # Create datasets\n",
    "    train_dataset = CornDataset(TRAIN_CSV, transform=train_transform)\n",
    "    val_dataset = CornDataset(VAL_CSV, transform=val_transform)\n",
    "\n",
    "    # Create dataloaders with optimized settings\n",
    "    train_loader = DataLoader(\n",
    "        train_dataset,\n",
    "        batch_size=batch_size,\n",
    "        shuffle=True,\n",
    "        num_workers=NUM_WORKERS,\n",
    "        pin_memory=True,\n",
    "        prefetch_factor=PREFETCH_FACTOR,\n",
    "        persistent_workers=True\n",
    "    )\n",
    "\n",
    "    val_loader = DataLoader(\n",
    "        val_dataset,\n",
    "        batch_size=batch_size,\n",
    "        shuffle=False,\n",
    "        num_workers=NUM_WORKERS,\n",
    "        pin_memory=True,\n",
    "        prefetch_factor=PREFETCH_FACTOR,\n",
    "        persistent_workers=True\n",
    "    )\n",
    "\n",
    "    return train_loader, val_loader\n",
    "\n",
    "# Function to perform label encoding\n",
    "def perform_label_encoding():\n",
    "    train_data = pd.read_csv(TRAIN_CSV)\n",
    "    val_data = pd.read_csv(VAL_CSV)\n",
    "\n",
    "    # Combine all categories\n",
    "    all_categories = pd.concat([train_data['Category'], val_data['Category']]).unique()\n",
    "\n",
    "    # Create encoding\n",
    "    label_encoder = LabelEncoder()\n",
    "    label_encoder.fit(all_categories)\n",
    "\n",
    "    # Create label_to_idx dictionary\n",
    "    label_to_idx = {category: int(idx) for category, idx in zip(all_categories, label_encoder.transform(all_categories))}\n",
    "\n",
    "    # Save to json\n",
    "    with open(LABEL_JSON, 'w') as f:\n",
    "        json.dump(label_to_idx, f)\n",
    "\n",
    "    print(f\"Label encoding saved to {LABEL_JSON}\")\n",
    "    return len(label_to_idx)\n",
    "\n",
    "# Function to train for one epoch with mixed precision\n",
    "def train_epoch(model, loader, criterion, optimizer, device, scaler):\n",
    "    model.train()\n",
    "    running_loss = 0.0\n",
    "    correct = 0\n",
    "    total = 0\n",
    "\n",
    "    for inputs, labels in tqdm(loader, desc=\"Training\"):\n",
    "        inputs, labels = inputs.to(device, non_blocking=True), labels.to(device, non_blocking=True)\n",
    "\n",
    "        # Zero the parameter gradients\n",
    "        optimizer.zero_grad(set_to_none=True)  # More efficient than zero_grad()\n",
    "\n",
    "        # Forward pass with mixed precision\n",
    "        with amp.autocast():\n",
    "            outputs = model(inputs)\n",
    "            loss = criterion(outputs, labels)\n",
    "\n",
    "        # Backward and optimize with scaled gradients\n",
    "        scaler.scale(loss).backward()\n",
    "        scaler.step(optimizer)\n",
    "        scaler.update()\n",
    "\n",
    "        # Statistics\n",
    "        running_loss += loss.item() * inputs.size(0)\n",
    "        _, predicted = torch.max(outputs, 1)\n",
    "        total += labels.size(0)\n",
    "        correct += (predicted == labels).sum().item()\n",
    "\n",
    "    epoch_loss = running_loss / total\n",
    "    epoch_acc = correct / total\n",
    "    return epoch_loss, epoch_acc\n",
    "\n",
    "# Function to validate with mixed precision\n",
    "def validate(model, loader, criterion, device):\n",
    "    model.eval()\n",
    "    running_loss = 0.0\n",
    "    correct = 0\n",
    "    total = 0\n",
    "\n",
    "    with torch.no_grad(), amp.autocast():\n",
    "        for inputs, labels in tqdm(loader, desc=\"Validating\"):\n",
    "            inputs, labels = inputs.to(device, non_blocking=True), labels.to(device, non_blocking=True)\n",
    "\n",
    "            outputs = model(inputs)\n",
    "            loss = criterion(outputs, labels)\n",
    "\n",
    "            # Statistics\n",
    "            running_loss += loss.item() * inputs.size(0)\n",
    "            _, predicted = torch.max(outputs, 1)\n",
    "            total += labels.size(0)\n",
    "            correct += (predicted == labels).sum().item()\n",
    "\n",
    "    val_loss = running_loss / total\n",
    "    val_acc = correct / total\n",
    "    return val_loss, val_acc\n",
    "\n",
    "# Function to initialize the model\n",
    "def create_model(num_classes, dropout_rate=0.5):\n",
    "    # Load with higher performance settings\n",
    "    try:\n",
    "        model = models.resnet50(weights=models.ResNet50_Weights.IMAGENET1K_V1)\n",
    "    except:\n",
    "        model = models.resnet50(pretrained=True)\n",
    "\n",
    "    # Freeze early layers\n",
    "    for param in list(model.parameters())[:-4]:  # Freeze fewer layers\n",
    "        param.requires_grad = False\n",
    "\n",
    "    # Replace the final fully connected layer\n",
    "    num_ftrs = model.fc.in_features\n",
    "    model.fc = nn.Sequential(\n",
    "        nn.Dropout(dropout_rate),\n",
    "        nn.Linear(num_ftrs, num_classes)\n",
    "    )\n",
    "\n",
    "    # Use channels_last memory format for better performance on A100\n",
    "    model = model.to(device, memory_format=torch.channels_last)\n",
    "    return model\n",
    "\n",
    "# Objective function for Optuna\n",
    "def objective(trial, num_classes):\n",
    "    # Define hyperparameters to optimize\n",
    "    batch_size = trial.suggest_categorical('batch_size', BATCH_SIZES)\n",
    "    learning_rate = trial.suggest_float('learning_rate', 1e-5, 1e-3, log=True)\n",
    "    dropout_rate = trial.suggest_float('dropout_rate', 0.2, 0.7)\n",
    "    weight_decay = trial.suggest_float('weight_decay', 1e-5, 1e-3, log=True)\n",
    "\n",
    "    # Create model and dataloaders\n",
    "    model = create_model(num_classes, dropout_rate)\n",
    "    train_loader, val_loader = create_data_loaders(batch_size)\n",
    "\n",
    "    # Define loss function and optimizer\n",
    "    criterion = nn.CrossEntropyLoss()\n",
    "    optimizer = optim.AdamW(model.parameters(), lr=learning_rate, weight_decay=weight_decay)\n",
    "\n",
    "    # Create gradient scaler for mixed precision training\n",
    "    scaler = amp.GradScaler()\n",
    "\n",
    "    # Train for a few epochs\n",
    "    best_val_acc = 0\n",
    "    patience = 0\n",
    "    max_patience = 3\n",
    "\n",
    "    for epoch in range(10):  # Maximum 10 epochs per trial\n",
    "        train_loss, train_acc = train_epoch(model, train_loader, criterion, optimizer, device, scaler)\n",
    "        val_loss, val_acc = validate(model, val_loader, criterion, device)\n",
    "\n",
    "        print(f\"Epoch {epoch+1}, Train Loss: {train_loss:.4f}, Train Acc: {train_acc:.4f}, \"\n",
    "              f\"Val Loss: {val_loss:.4f}, Val Acc: {val_acc:.4f}\")\n",
    "\n",
    "        # Print GPU memory usage\n",
    "        if torch.cuda.is_available():\n",
    "            print(f\"GPU Memory: {torch.cuda.memory_allocated(0)/1e9:.2f}GB / {torch.cuda.get_device_properties(0).total_memory/1e9:.2f}GB\")\n",
    "\n",
    "        trial.report(val_acc, epoch)\n",
    "\n",
    "        # Handle pruning\n",
    "        if trial.should_prune():\n",
    "            raise optuna.exceptions.TrialPruned()\n",
    "\n",
    "        # Early stopping\n",
    "        if val_acc > best_val_acc:\n",
    "            best_val_acc = val_acc\n",
    "            patience = 0\n",
    "\n",
    "            # Save the current model as a checkpoint for this trial\n",
    "            trial_model_path = f\"trial_{trial.number}_model.pth\"\n",
    "            torch.save(model.state_dict(), trial_model_path)\n",
    "        else:\n",
    "            patience += 1\n",
    "            if patience >= max_patience:\n",
    "                print(f\"Early stopping at epoch {epoch+1}\")\n",
    "                break\n",
    "\n",
    "    return best_val_acc\n",
    "\n",
    "# Main function\n",
    "def main():\n",
    "    # Perform label encoding first\n",
    "    num_classes = perform_label_encoding()\n",
    "    print(f\"Number of classes: {num_classes}\")\n",
    "\n",
    "    # Create the optuna study with A100-optimized settings\n",
    "    study = optuna.create_study(direction='maximize', sampler=TPESampler())\n",
    "\n",
    "    # Run fewer trials but with more GPU utilization\n",
    "    n_trials = 30 # 10\n",
    "    print(f\"Running {n_trials} trials with larger batch sizes to maximize GPU usage\")\n",
    "\n",
    "    # Pass num_classes to objective function using a lambda function\n",
    "    study.optimize(lambda trial: objective(trial, num_classes), n_trials=n_trials)\n",
    "\n",
    "    # Get the best parameters\n",
    "    best_params = study.best_params\n",
    "    best_value = study.best_value\n",
    "    print(f\"Best trial: {study.best_trial.number}\")\n",
    "    print(f\"Best validation accuracy: {best_value:.4f}\")\n",
    "    print(f\"Best hyperparameters: {best_params}\")\n",
    "\n",
    "    # Load the best model from the best trial\n",
    "    best_model = create_model(num_classes, best_params['dropout_rate'])\n",
    "    best_model.load_state_dict(torch.load(f\"trial_{study.best_trial.number}_model.pth\"))\n",
    "\n",
    "    # Save the best model\n",
    "    torch.save(best_model.state_dict(), BEST_MODEL_PATH)\n",
    "    print(f\"Best model saved to {BEST_MODEL_PATH}\")\n",
    "\n",
    "    # Clean up trial model files\n",
    "    for trial in study.trials:\n",
    "        trial_model_path = f\"trial_{trial.number}_model.pth\"\n",
    "        if os.path.exists(trial_model_path):\n",
    "            os.remove(trial_model_path)\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Predictions Phase"
   ],
   "metadata": {
    "id": "E2TnucJDxCsy"
   }
  },
  {
   "cell_type": "code",
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torchvision.models as models\n",
    "import torchvision.transforms as transforms\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from PIL import Image\n",
    "import pandas as pd\n",
    "import requests\n",
    "from io import BytesIO\n",
    "import json\n",
    "import logging\n",
    "import os\n",
    "import time\n",
    "from google.colab import drive\n",
    "drive.mount('/content/gdrive')\n",
    "\n",
    "# Setup logging\n",
    "logging.basicConfig(\n",
    "    level=logging.INFO,\n",
    "    format='%(asctime)s - %(levelname)s - %(message)s',\n",
    "    handlers=[\n",
    "        logging.FileHandler('prediction.log'),\n",
    "        logging.StreamHandler()\n",
    "    ]\n",
    ")\n",
    "logger = logging.getLogger(__name__)\n",
    "\n",
    "class TestImageDataset(Dataset):\n",
    "    \"\"\"Custom Dataset for loading test images\"\"\"\n",
    "    def __init__(self, csv_file, feature_col, transform=None):\n",
    "        self.data = pd.read_csv(csv_file)\n",
    "        self.feature_col = feature_col\n",
    "        self.transform = transform\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.data)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        try:\n",
    "            img_url = self.data.iloc[idx][self.feature_col]\n",
    "\n",
    "            # Download and open image\n",
    "            response = requests.get(img_url, timeout=10)\n",
    "            if response.status_code != 200:\n",
    "                raise ValueError(f\"Failed to fetch image: HTTP {response.status_code}\")\n",
    "\n",
    "            img = Image.open(BytesIO(response.content)).convert('RGB')\n",
    "\n",
    "            if self.transform:\n",
    "                img = self.transform(img)\n",
    "\n",
    "            return img, idx\n",
    "\n",
    "        except Exception as e:\n",
    "            logger.error(f\"Error loading image at index {idx}: {str(e)}\")\n",
    "            raise\n",
    "\n",
    "def load_model_and_labels(model_path, label_to_idx_path):\n",
    "    \"\"\"Load the trained model and label mapping\"\"\"\n",
    "    try:\n",
    "        # Load label mapping\n",
    "        with open(label_to_idx_path, 'r') as f:\n",
    "            label_to_idx = json.load(f)\n",
    "\n",
    "        # Create inverse mapping\n",
    "        idx_to_label = {v: k for k, v in label_to_idx.items()}\n",
    "\n",
    "        # Initialize model\n",
    "        model = models.resnet50(weights=None)\n",
    "        model.fc = nn.Sequential(\n",
    "            nn.Dropout(0.5),\n",
    "            nn.Linear(model.fc.in_features, len(label_to_idx))\n",
    "        )\n",
    "\n",
    "        # Load trained weights\n",
    "        model.load_state_dict(torch.load(model_path))\n",
    "\n",
    "        return model, idx_to_label\n",
    "\n",
    "    except Exception as e:\n",
    "        logger.error(f\"Error loading model and labels: {str(e)}\")\n",
    "        raise\n",
    "\n",
    "def predict_images(test_set_path, model_path, label_to_idx_path, batch_size,\n",
    "                  prediction_col_name, output_path, feature_col='Image'):\n",
    "    \"\"\"\n",
    "    Make predictions on test images and save results\n",
    "\n",
    "    Parameters:\n",
    "    - test_set_path: path to test CSV file\n",
    "    - model_path: path to trained model weights\n",
    "    - label_to_idx_path: path to label mapping JSON\n",
    "    - batch_size: batch size for predictions\n",
    "    - prediction_col_name: name for the new predictions column\n",
    "    - output_path: path to save predictions CSV\n",
    "    - feature_col: name of column containing image URLs\n",
    "\n",
    "    Returns:\n",
    "    - result_df: DataFrame with predictions\n",
    "    - execution_time: Time taken for predictions in seconds\n",
    "    - prediction_cost: Cost of predictions based on execution time\n",
    "    \"\"\"\n",
    "    try:\n",
    "        # Start timing\n",
    "        start_time = time.time()\n",
    "\n",
    "        device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "        logger.info(f\"Using device: {device}\")\n",
    "\n",
    "        # Load test data\n",
    "        test_df = pd.read_csv(test_set_path)\n",
    "        logger.info(f\"Loaded test set with {len(test_df)} images\")\n",
    "\n",
    "        # Create transforms for test images\n",
    "        test_transform = transforms.Compose([\n",
    "            transforms.Resize((224, 224)),  # Standard ResNet input size\n",
    "            transforms.ToTensor(),\n",
    "            transforms.Normalize(mean=[0.485, 0.456, 0.406],\n",
    "                              std=[0.229, 0.224, 0.225])\n",
    "        ])\n",
    "\n",
    "        # Create dataset and dataloader\n",
    "        test_dataset = TestImageDataset(test_set_path, feature_col, test_transform)\n",
    "        test_loader = DataLoader(test_dataset,\n",
    "                               batch_size=batch_size,\n",
    "                               shuffle=False,\n",
    "                               num_workers=4)\n",
    "\n",
    "        # Load model and label mapping\n",
    "        model, idx_to_label = load_model_and_labels(model_path, label_to_idx_path)\n",
    "        model = model.to(device)\n",
    "        model.eval()\n",
    "\n",
    "        # Make predictions\n",
    "        predictions = []\n",
    "        with torch.no_grad():\n",
    "            for batch_images, batch_indices in test_loader:\n",
    "                batch_images = batch_images.to(device)\n",
    "                outputs = model(batch_images)\n",
    "                _, predicted = torch.max(outputs.data, 1)\n",
    "\n",
    "                # Convert indices to labels\n",
    "                batch_predictions = [idx_to_label[idx.item()]\n",
    "                                  for idx in predicted]\n",
    "\n",
    "                # Store predictions with their indices\n",
    "                for idx, pred in zip(batch_indices, batch_predictions):\n",
    "                    predictions.append((idx.item(), pred))\n",
    "\n",
    "        # Sort predictions by index to maintain original order\n",
    "        predictions.sort(key=lambda x: x[0])\n",
    "        predicted_labels = [pred[1] for pred in predictions]\n",
    "\n",
    "        # Add predictions to dataframe\n",
    "        test_df[prediction_col_name] = predicted_labels\n",
    "\n",
    "        # Save results\n",
    "        test_df.to_csv(output_path, index=False)\n",
    "\n",
    "        # Calculate execution time and cost\n",
    "        execution_time = time.time() - start_time\n",
    "        prediction_cost = 0.000281392488 * execution_time\n",
    "\n",
    "        logger.info(f\"Predictions saved to {output_path}\")\n",
    "        logger.info(f\"Prediction time: {execution_time:.2f} seconds\")\n",
    "        logger.info(f\"Prediction cost: ${prediction_cost:.6f}\")\n",
    "\n",
    "        return test_df, execution_time, prediction_cost\n",
    "\n",
    "    except Exception as e:\n",
    "        logger.error(f\"Error in prediction pipeline: {str(e)}\")\n",
    "        raise\n",
    "\n",
    "absolute_path = \"/content/gdrive/My Drive/Projects/Multimodal/\"\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    test_params = {\n",
    "        'test_set_path': absolute_path + 'Datasets/Corn_test_set_100.csv',\n",
    "        'model_path': absolute_path + 'Datasets/corn-best_resnet50_model-100.pth',\n",
    "        'label_to_idx_path': absolute_path + 'Datasets/corn-label_to_idx-100.json',\n",
    "        'batch_size': 16,\n",
    "        'prediction_col_name': 'ResNet50-Predictions-Bayesian-Optimization',\n",
    "        'output_path': absolute_path + 'Datasets/Corn-test_set_100_with_predictions.csv'\n",
    "    }\n",
    "\n",
    "    # Run predictions\n",
    "    result_df, execution_time, prediction_cost = predict_images(**test_params)\n",
    "\n",
    "    print(\"\\nPrediction Results Summary:\")\n",
    "    print(f\"Total prediction time: {execution_time:.2f} seconds\")\n",
    "    print(f\"Total prediction cost: ${prediction_cost:.6f}\")"
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "8eHXQjyjxHEA",
    "executionInfo": {
     "status": "ok",
     "timestamp": 1742461722049,
     "user_tz": -120,
     "elapsed": 26796,
     "user": {
      "displayName": "Konstantinos Roumeliotis",
      "userId": "17264923090131634662"
     }
    },
    "outputId": "50298efb-5236-47e0-a8fc-694ee7cbe599"
   },
   "execution_count": 2,
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Drive already mounted at /content/gdrive; to attempt to forcibly remount, call drive.mount(\"/content/gdrive\", force_remount=True).\n",
      "\n",
      "Prediction Results Summary:\n",
      "Total prediction time: 25.24 seconds\n",
      "Total prediction cost: $0.007101\n"
     ]
    }
   ]
  },
  {
   "cell_type": "markdown",
   "source": [],
   "metadata": {
    "id": "E6X06e8et-4G"
   }
  }
 ]
}
